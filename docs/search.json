[
  {
    "objectID": "publications/xavierRegioesSaudeNo2019.html#reference",
    "href": "publications/xavierRegioesSaudeNo2019.html#reference",
    "title": "As Regiões de Saúde no Brasil segundo internações: método para apoio na regionalização de saúde",
    "section": "Reference",
    "text": "Reference\n\n\nXAVIER, D. R. et al. As Regiões de Saúde no Brasil segundo internações: método para apoio na regionalização de saúde. Cadernos de Saúde Pública, v. 35, p. e00076118, Jun. 2019."
  },
  {
    "objectID": "publications/xavierRegioesSaudeNo2019.html#abstract",
    "href": "publications/xavierRegioesSaudeNo2019.html#abstract",
    "title": "As Regiões de Saúde no Brasil segundo internações: método para apoio na regionalização de saúde",
    "section": "Abstract",
    "text": "Abstract\nThis study addressed health regionalization on various spatial scales based on patient flow. The article analyzed data through data linkage on the origin and destination of admissions at the municipal level in Brazil in 2016. The analysis is based on graph theory and uses a modularity algorithm that seeks to group municipalities in communities with a large number of interlinks. The algorithm optimizes the number of hospital admissions and discharges, taking patient flow into account. The results are shown, considering different political and administrative spatial structures. Considering patient flow without spatial restrictions, 29 communities were created in the country, compared to 64 communities when the boundaries of the major geographic regions were respected, and 164 when considering only patient flows within the respective states. The results show the importance of historically constituted regions, ignoring formal administrative boundaries, in order to implement access to health services. They also reveal adherence to administrative boundaries in many states of Brazil, demonstrating this spatial scale’s importance in the context of access to hospital admissions. The methodology makes relevant contributions to regional health planning."
  },
  {
    "objectID": "publications/szwarcwaldAdesaoMedidasRestricao2020a.html#reference",
    "href": "publications/szwarcwaldAdesaoMedidasRestricao2020a.html#reference",
    "title": "Adesão às medidas de restrição de contato físico e disseminação da COVID-19 no Brasil",
    "section": "Reference",
    "text": "Reference\n\n\nSZWARCWALD, C. L. et al. Adesão às medidas de restrição de contato físico e disseminação da COVID-19 no Brasil. Epidemiologia e Serviços de Saúde, v. 29, p. e2020432, Nov. 2020."
  },
  {
    "objectID": "publications/szwarcwaldAdesaoMedidasRestricao2020a.html#abstract",
    "href": "publications/szwarcwaldAdesaoMedidasRestricao2020a.html#abstract",
    "title": "Adesão às medidas de restrição de contato físico e disseminação da COVID-19 no Brasil",
    "section": "Abstract",
    "text": "Abstract\nObjetivo: Analisar a adesão da população às medidas de restrição de contato físico e disseminação da COVID-19 no Brasil. Métodos: Inquérito de saúde, realizado pela internet, com amostragem em cadeia, no período de 24 de abril a 24 de maio de 2020. A intensidade da adesão à restrição de contato físico foi analisada segundo características sociodemográficas, utilizando-se modelos de regressão logística para investigar associações com ‘Nenhuma/pouca adesão’. Resultados: Dos 45.161 participantes, 74,2% (73,8-74,6%) relataram intensa adesão às medidas. O grupo que não aderiu às medidas foi composto homens (31,7%), com idade de 30 a 49 anos (36,4%), baixa escolaridade (33,0%), trabalhando durante a pandemia (81,3%), residentes nas regiões Norte (28,1%) e Centro-Oeste (28,5%) do país. Houve importante redução das taxas de crescimento diário, de 45,4 para 5,0%. Conclusão: Grande parte da população brasileira aderiu às medidas de restrição de contato físico, o que, possivelmente, contribuiu para reduzir a disseminação da COVID-19."
  },
  {
    "objectID": "publications/soutoDatasetInfantMortality2023.html#reference",
    "href": "publications/soutoDatasetInfantMortality2023.html#reference",
    "title": "Dataset on infant mortality rates in Brazil",
    "section": "Reference",
    "text": "Reference\n\n\nSOUTO, G. et al. Dataset on infant mortality rates in Brazil. BMC Research Notes, v. 16, n. 1, p. 149, Jul. 2023."
  },
  {
    "objectID": "publications/soutoDatasetInfantMortality2023.html#abstract",
    "href": "publications/soutoDatasetInfantMortality2023.html#abstract",
    "title": "Dataset on infant mortality rates in Brazil",
    "section": "Abstract",
    "text": "Abstract\n\nObjectives\nSurveillance of infant and fetal deaths is of paramount importance in thinking about government strategies to reduce these rates, provide greater visibility of these mortality figures in the country, enable the adoption of prevention measures, as well as contribute to a better record of deaths.\n\n\nData description\nThe dataset comprises fetal, neonatal, early neonatal, late neonatal, and perinatal Mortality Rates of Brazilian municipalities with their respective information, between 2010 to 2020, aggregated by epidemiological week."
  },
  {
    "objectID": "publications/sallesComprehensiveIntegratedDataset2023a.html#reference",
    "href": "publications/sallesComprehensiveIntegratedDataset2023a.html#reference",
    "title": "A comprehensive integrated dataset on Brazilian health facilities: from 2005 to 2021",
    "section": "Reference",
    "text": "Reference\n\n\nSALLES, R. et al. A comprehensive integrated dataset on Brazilian health facilities: From 2005 to 2021. BMC Research Notes, v. 16, n. 1, p. 151, Jul. 2023."
  },
  {
    "objectID": "publications/sallesComprehensiveIntegratedDataset2023a.html#abstract",
    "href": "publications/sallesComprehensiveIntegratedDataset2023a.html#abstract",
    "title": "A comprehensive integrated dataset on Brazilian health facilities: from 2005 to 2021",
    "section": "Abstract",
    "text": "Abstract\n\nObjectives\nThe National Registry of Healthcare Facilities is a system with the registry of every healthcare facility in Brazil with information on the capacity building and healthcare workforce regarding its public or private nature. Despite being publicly available, it can only be accessed in separated disjoint tables, with different primary units of analysis. The objective is to offer an interoperable dataset containing monthly data from 2005 to 2021 with information on healthcare facilities, including their physical and human resources, services and teams, enriched with municipal information.\n\n\nData description\nDatabase with historical data and geographic information for each health facility in Brazil. It is composed by 5 distinct tables, organized according to combinations of time, space, and types of resources, services and teams. This database opens up a range of possibilities for research topics, from case studies in a single health facility and period, analysis of a group of health facilities with characteristics of interest, to a broader study using the entire dataset and aggregated data by municipality. Furthermore, the fact that there is a row for each health facility/month/ year facilitates the integration with other datasets from the Brazilian healthcare system. In addition to being a potential object of study in the health area, the dataset is also convenient in data science, especially for studies focused on time series."
  },
  {
    "objectID": "publications/saldanhaPesquisaCientificaNa2022.html#reference",
    "href": "publications/saldanhaPesquisaCientificaNa2022.html#reference",
    "title": "Book review: A pesquisa científica na era do Big data: cinco maneiras que mostram como o Big data prejudica a ciência, e como podemos salvá-la",
    "section": "Reference",
    "text": "Reference\n\n\nSALDANHA, R. D. F. A pesquisa científica na era do Big data: cinco maneiras que mostram como o Big data prejudica a ciência, e como podemos salvá-la. Revista Eletrônica de Comunicação, Informação & Inovação em Saúde, v. 16, n. 3, p. 742–745, Sep. 2022."
  },
  {
    "objectID": "publications/saldanhaPesquisaCientificaNa2022.html#abstract",
    "href": "publications/saldanhaPesquisaCientificaNa2022.html#abstract",
    "title": "Book review: A pesquisa científica na era do Big data: cinco maneiras que mostram como o Big data prejudica a ciência, e como podemos salvá-la",
    "section": "Abstract",
    "text": "Abstract\nThe book titled A pesquisa científica na era do Big Data: cinco maneiras que mostram como o Big Data prejudica a ciência, e como podemos salvá-la [The scientific research in the age of Big Data: five ways that show how the Big Data harms the science, and how we can save it], by Sabina Leonelli, published in 2002, by Editora Fiocruz, explores in its chapters the definitions of Big Data and its negative impacts on scientific research. Then, the author reveals a new epistemological approach to Big data and finally she presents a set of proposals for developing a good scientific research. The literature review and updating of definitions as well as the important reflections and questions for a conscious use of Big data in scientific research make the work an important contribution to the researcher’s library of the information and communication about health."
  },
  {
    "objectID": "publications/saldanhaEstudoAnaliseRede2019.html#reference",
    "href": "publications/saldanhaEstudoAnaliseRede2019.html#reference",
    "title": "Estudo de análise de rede do fluxo de pacientes de câncer de mama no Brasil entre 2014 e 2016",
    "section": "Reference",
    "text": "Reference\n\n\nSALDANHA, R. DE F. et al. Estudo de análise de rede do fluxo de pacientes de câncer de mama no Brasil entre 2014 e 2016. Cadernos de Saúde Pública, v. 35, p. e00090918, Jul. 2019."
  },
  {
    "objectID": "publications/saldanhaEstudoAnaliseRede2019.html#abstract",
    "href": "publications/saldanhaEstudoAnaliseRede2019.html#abstract",
    "title": "Estudo de análise de rede do fluxo de pacientes de câncer de mama no Brasil entre 2014 e 2016",
    "section": "Abstract",
    "text": "Abstract\nThis study aims to analyze the flow of breast cancer patients treated outside of their municipality of residence, based on hospital admissions and chemotherapy and radiotherapy in the Brazilian Unified National Health System (SUS) from 2014 to 2016. Network analysis was used, considering the municipality of residence and of treatment as nodes in a graph, thus consisting of a “health system organizational network study”. In addition, highway distances and travel time were estimated via the best feasible route according to the Open Street Maps highway project. According to the results, 51.34% of breast cancer patients in Brazil were treated outside their municipality of residence, following regionalized flows that respect state borders, generally towards the state capital or other large cities. The results also point to specific exceptions, where some municipalities occupy outstanding positions that extrapolate state borders. Median travel time from the municipality of residence to the municipality of care was nearly 3 hours, and 75% of trips totaled 324km for chemotherapy, 287km for radiotherapy, and 282km for hospitalizations. These results are indicative of the difficulties in access to oncology services, potentially aggravating the illness experience with cancer in terms of impact on the individuals and their families."
  },
  {
    "objectID": "publications/saldanhaCienciaDadosBig2021a.html#reference",
    "href": "publications/saldanhaCienciaDadosBig2021a.html#reference",
    "title": "Ciência de dados e big data: o que isso significa para estudos populacionais e da saúde?",
    "section": "Reference",
    "text": "Reference\n\n\nSALDANHA, R. DE F.; BARCELLOS, C.; PEDROSO, M. DE M. Ciência de dados e big data: o que isso significa para estudos populacionais e da saúde? Cadernos Saúde Coletiva, v. 29, p. 51–58, Nov. 2021."
  },
  {
    "objectID": "publications/saldanhaCienciaDadosBig2021a.html#abstract",
    "href": "publications/saldanhaCienciaDadosBig2021a.html#abstract",
    "title": "Ciência de dados e big data: o que isso significa para estudos populacionais e da saúde?",
    "section": "Abstract",
    "text": "Abstract\n\nBackground\nThe term big data is no longer new in the academic environment and has become more common in scientific publications and research grants, leading to a profound revision of the way science is being made and taught.\n\n\nObjective\nTo reflect on the possible changes that data science can induce in population and health related studies\n\n\nMethod\nTo foster this debate, scientific articles selected from the big data field in health and demography were contrasted with books and other scientific productions.\n\n\nResults\nIt is argued that volume is not the most promising characteristic of big data for population and health related studies, but rather the complexity of data and the possibilities of integration with traditional studies by means of interdisciplinary teams.\n\n\nConclusion\nIn population and health related studies, the possibilities of integration between new and traditional methods are broad, and include new toolboxes for analysis, monitoring, prediction of events (cases) and health-disease processes in the population, and for the study of sociodemographic and environmental determinants."
  },
  {
    "objectID": "publications/mosnierResurgenceRiskMalaria2020a.html#reference",
    "href": "publications/mosnierResurgenceRiskMalaria2020a.html#reference",
    "title": "Resurgence risk for malaria, and the characterization of a recent outbreak in an Amazonian border area between French Guiana and Brazil",
    "section": "Reference",
    "text": "Reference\n\n\nMOSNIER, E. et al. Resurgence risk for malaria, and the characterization of a recent outbreak in an Amazonian border area between French Guiana and Brazil. BMC Infectious Diseases, v. 20, n. 1, p. 373, May 2020."
  },
  {
    "objectID": "publications/mosnierResurgenceRiskMalaria2020a.html#abstract",
    "href": "publications/mosnierResurgenceRiskMalaria2020a.html#abstract",
    "title": "Resurgence risk for malaria, and the characterization of a recent outbreak in an Amazonian border area between French Guiana and Brazil",
    "section": "Abstract",
    "text": "Abstract\n\nBackground\nIn 2017, inhabitants along the border between French Guiana and Brazil were affected by a malaria outbreak primarily due to Plasmodium vivax (Pv). While malaria cases have steadily declined between 2005 and 2016 in this Amazonian region, a resurgence was observed in 2017.\n\n\nMethods\nTwo investigations were performed according to different spatial scales and information details: (1) a local study on the French Guiana border, which enabled a thorough investigation of malaria cases treated at a local village health center and the entomological circumstances in the most affected neighborhood, and (2) a regional and cross-border study, which enabled exploration of the regional spatiotemporal epidemic dynamic. Number and location of malaria cases were estimated using French and Brazilian surveillance systems.\n\n\nResults\nOn the French Guianese side of the border in Saint-Georges de l’Oyapock, the attack rate was 5.5% (n = 4000), reaching 51.4% (n = 175) in one Indigenous neighborhood. Entomological findings suggest a peak of Anopheles darlingi density in August and September. Two female An. darlingi (n = 1104, 0.18%) were found to be Pvpositive during this peak. During the same period, aggregated data from passive surveillance conducted by Brazilian and French Guianese border health centers identified 1566 cases of Pv infection. Temporal distribution during the 2007–2018 period displayed seasonal patterns with a peak in November 2017. Four clusters were identified among epidemic profiles of cross-border area localities. All localities of the first two clusters were Brazilian. The localization of the first cluster suggests an onset of the outbreak in an Indigenous reservation, subsequently expanding to French Indigenous neighborhoods and non-Native communities.\n\n\nConclusions\nThe current findings demonstrate a potential increase in malaria cases in an area with otherwise declining numbers. This is a transborder region where human mobility and remote populations challenge malaria control programs. This investigation illustrates the importance of international border surveillance and collaboration for malaria control, particularly in Indigenous villages and mobile populations."
  },
  {
    "objectID": "publications/guimaraesItTimeTalk2020b.html#reference",
    "href": "publications/guimaraesItTimeTalk2020b.html#reference",
    "title": "Is it time to talk about the end of social distancing? A joinpoint analysis of COVID-19 time series in Brazilian capitals",
    "section": "Reference",
    "text": "Reference\n\n\nGUIMARÃES, R. M. et al. Is it time to talk about the end of social distancing? A joinpoint analysis of COVID-19 time series in Brazilian capitals. Revista da Sociedade Brasileira de Medicina Tropical, v. 53, p. e20200469, Sep. 2020."
  },
  {
    "objectID": "publications/guimaraesItTimeTalk2020b.html#abstract",
    "href": "publications/guimaraesItTimeTalk2020b.html#abstract",
    "title": "Is it time to talk about the end of social distancing? A joinpoint analysis of COVID-19 time series in Brazilian capitals",
    "section": "Abstract",
    "text": "Abstract\n\nIntroduction\nMonitoring coronavirus disease (COVID-19)-related infections and deaths in Brazil is controversial, with increasing pressure to ease social distance measures. However, no evidence of a sustained, widespread fall in cases exists.\n\n\nMethods\nWe used segmented (joinpoint) regression analysis to describe the behavior of COVID-19 infections in Brazilian capital cities.\n\n\nResults\nAll capitals showed an exponential or a near-exponential increase in cases through May. A decline in reported cases was subsequently noted in 20 cities but was only significant for 8 (29.6%) and was followed in two by a renewed increase.\n\n\nConclusions\nCaution is warranted when considering the relaxation of restrictions."
  },
  {
    "objectID": "publications/guimaraesHowOvercomeStagnation2022a.html#reference",
    "href": "publications/guimaraesHowOvercomeStagnation2022a.html#reference",
    "title": "How to overcome the stagnation of the first dose vaccine coverage curve against coronavirus disease 2019 in Brazil?",
    "section": "Reference",
    "text": "Reference\n\n\nGUIMARÃES, R. M. et al. How to overcome the stagnation of the first dose vaccine coverage curve against coronavirus disease 2019 in Brazil? Revista da Sociedade Brasileira de Medicina Tropical, v. 55, p. e0722, Jun. 2022."
  },
  {
    "objectID": "publications/guimaraesHowOvercomeStagnation2022a.html#abstract",
    "href": "publications/guimaraesHowOvercomeStagnation2022a.html#abstract",
    "title": "How to overcome the stagnation of the first dose vaccine coverage curve against coronavirus disease 2019 in Brazil?",
    "section": "Abstract",
    "text": "Abstract\nBackground: A large percentage of the population has not yet started vaccination, for which the increase in coverage is almost null. Methods: We used segmented regression analysis to estimate trends in the first dose coverage curve. Results: There has been a slowdown in the application of the first doses in Brazil since epidemiological week 36 (average percent change [APC] 0.83%, 95% confidence interval [CI] 0.75-0.91%), with a trend close to stagnation. Conclusions: It is important to develop strategies to increase access to vaccination posts. Furthermore, it is recommended to expand vaccination to children, thereby increasing the eligible population."
  },
  {
    "objectID": "publications/fonsecaGeographicAccessibilityCancer2022a.html#reference",
    "href": "publications/fonsecaGeographicAccessibilityCancer2022a.html#reference",
    "title": "Geographic accessibility to cancer treatment in Brazil: A network analysis",
    "section": "Reference",
    "text": "Reference\n\n\nFONSECA, B. DE P. et al. Geographic accessibility to cancer treatment in Brazil: A network analysis. The Lancet Regional Health - Americas, v. 7, p. 100153, Mar. 2022."
  },
  {
    "objectID": "publications/fonsecaGeographicAccessibilityCancer2022a.html#abstract",
    "href": "publications/fonsecaGeographicAccessibilityCancer2022a.html#abstract",
    "title": "Geographic accessibility to cancer treatment in Brazil: A network analysis",
    "section": "Abstract",
    "text": "Abstract\n\nBackground\nGeographic accessibility to healthcare services is a fundamental component in achieving universal health coverage, the central commitment of the Brazilian Unified Health System (SUS). For cancer patients, poor accessibility has been associated with inadequate treatment, worse prognosis, and poorer quality of life.\n\n\nMethods\nWe explored nationwide healthcare data from the SUS health information systems, and mapped the geographic accessibility to cancer treatment in two time-frames: 2009–2010 and 2017–2018. We applied social network analysis (SNA) to estimate the commuting route, flow, and distances travelled by cancer patients to undergo surgical, radiotherapy, and chemotherapy treatment.\n\n\nFindings\nA total of 12,751,728 treatment procedures were analyzed. Overall, more than half of the patients (49·2 to 60·7%) needed to travel beyond their municipality of residence for treatment, a fact that did not change over time. Marked regional differences were observed, as patients living in the northern and midwestern regions of the country had to travel longer distances (weighted average of 296 to 870 km). Cancer care hubs and attraction poles were mostly identified in the southeast and northeast regions, with Barretos being the main hub for all types of treatment throughout time.\n\n\nInterpretation\nImportant regional disparities in the accessibility to cancer treatment in Brazil were revealed, suggesting the need to review the distribution of specialized care in the country. The data presented here contribute to ongoing research on improving access to cancer care and can provide reference to other countries, offering relevant data for oncological and healthcare service evaluation, monitoring, and strategic planning.\n\n\nFunding\nThis work was funded by the Oswaldo Cruz Foundation - Fiocruz (Inova - no. 8451635123 to BPF) and the National Council for Scientific and Technological Development - CNPq (no. 407060/2018–9 to BPF); Coordination for the Improvement of Higher Education Personnel – CAPES (scholarship to PCA, Finance Code 001); and Instituto Nacional de Ciência e Tecnologia de Inovação em Doenças de Populações Negligenciadas (INCT-IDPN)."
  },
  {
    "objectID": "publications/baroniNeonatalMortalityRates2021b.html#reference",
    "href": "publications/baroniNeonatalMortalityRates2021b.html#reference",
    "title": "Neonatal mortality rates in Brazilian municipalities: from 1996 to 2017",
    "section": "Reference",
    "text": "Reference\n\n\nBARONI, L. et al. Neonatal mortality rates in Brazilian municipalities: From 1996 to 2017. BMC Research Notes, v. 14, n. 1, p. 55, Feb. 2021."
  },
  {
    "objectID": "publications/baroniNeonatalMortalityRates2021b.html#abstract",
    "href": "publications/baroniNeonatalMortalityRates2021b.html#abstract",
    "title": "Neonatal mortality rates in Brazilian municipalities: from 1996 to 2017",
    "section": "Abstract",
    "text": "Abstract\nNeonatal mortality is a global public health problem, and the efforts to reduce child mortality is one of the goals of the 2030 Agenda for Sustainable Development, launched in 2015 by the United Nations. The availability of historical neonatal mortality rates (NMR) data in Brazilian municipalities is crucial to evaluate trends at local, regional and national level, identifying gaps and vulnerable territories. Therefore, the objective of this article is to offer an integrated dataset containing monthly data in a historical series from 1996 to 2017 with information on all births, neonatal deaths, and NMR (total, early and late components) enriched with information related to the municipality."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSubset modelling: A domain partitioning strategy for data-efficient machine-learning\n\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2023\n\n\nVitor Ribeiro, Eduardo Pena, Raphael Saldanha, Reza Akbarinia, Patrick Valduriez, Falaah Khan, Julia Stoyanovich, Fabio Porto\n\n\n\n\n\n\n  \n\n\n\n\nA comprehensive integrated dataset on Brazilian health facilities: from 2005 to 2021\n\n\n\n\n\n\n\n\n\n\n\n\nJul 20, 2023\n\n\nRebecca Salles, Victor Dornella, Raquel Gritz, Carlos Cardoso, Sérgio Cruz, Vinicius Kreischer, Carmen Bonifácio, Raphael Saldanha, Gabriel Souto, Matheus Miloski, Leandro Zirondi, Gizelton Alencar, Ariane Alves, Nelson Nieiro Neto, Jefferson Lima, Marcel Pedroso, Ronaldo Alves, Cristiano Boccolini\n\n\n\n\n\n\n  \n\n\n\n\nDataset on infant mortality rates in Brazil\n\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nGabriel Souto, Matheus Miloski, Carlos Cardoso, Vinicius Kreischer, Balthazar Paixão, Victor Ribeiro, Raquel Gritz, Lucas Carraro, Sérgio Cruz, Carmen Bonifácio, Raphael Saldanha, Leandro Zirondi, Gizelton Alencar, Ariane Alves, Nelson Nieiro Neto, Rebecca Salles, Jefferson Lima, Marcel Pedroso\n\n\n\n\n\n\n  \n\n\n\n\nBook review: A pesquisa científica na era do Big data: cinco maneiras que mostram como o Big data prejudica a ciência, e como podemos salvá-la\n\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nRaphael Saldanha\n\n\n\n\n\n\n  \n\n\n\n\nTemporal and spatial distribution trends of polio vaccine coverage in children in Brazil, 2011-2021\n\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2022\n\n\nTércia Silva, Ana Carolina de Sá, Elton Prates, Raphael Saldanha, Thales Silva, Antonia Teixeira, Mark Beinner, Suelen Oliveira, Anonio de Sá, Fernanda Matozinhos, Ed Vieira\n\n\n\n\n\n\n  \n\n\n\n\nComparison of sampling designs from the two editions of the Brazilian National Health Survey, 2013 and 2019\n\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2022\n\n\nPaulo Souza Júnior, Celia Szwarcwald, Wanessa Almeida, Giseli Damacena, Marcel Pedroso, Carlos Sousa, Igor Morais, Raphael Saldanha, Jefferson Lima, Sheila Stopa\n\n\n\n\n\n\n  \n\n\n\n\nHow to overcome the stagnation of the first dose vaccine coverage curve against coronavirus disease 2019 in Brazil?\n\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2022\n\n\nRaphael Guimarães, Diego Xavier, Raphael Saldanha, Monica Magalhães\n\n\n\n\n\n\n  \n\n\n\n\nGeographic accessibility to cancer treatment in Brazil: A network analysis\n\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\nBruna Fonseca, Priscila Albuquerque, Raphael Saldanha, Fabio Zicker\n\n\n\n\n\n\n  \n\n\n\n\nCiência de dados e big data: o que isso significa para estudos populacionais e da saúde?\n\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2021\n\n\nRaphael Saldanha, Christovam Barcellos, Marcel Pedroso\n\n\n\n\n\n\n  \n\n\n\n\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI\n\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2021\n\n\nBalthazar Paixão, Lais Baroni, Marcel Pedroso, Rebecca Sales, Luciana Escobar, Carlos Sousa, Raphael Saldanha, Jorge Soares, Rafaelli Coutinho, Fabio Porto, Eduardo Ogasawara\n\n\n\n\n\n\n  \n\n\n\n\nNeonatal mortality rates in Brazilian municipalities: from 1996 to 2017\n\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2021\n\n\nLais Baroni, Rebecca Sales, Samella Sales, Marcel Pedroso, Jefferson Lima, Igor Morais, Lucas Carraro, Raphael Saldanha, Carlos Sousa, Carlos Cardoso, Balthazar Paixão, Sérgio Cruz, Eduardo Ogasawara, Patricia Boccolini, Cristiano Boccolini\n\n\n\n\n\n\n  \n\n\n\n\nIncreasing impact of COVID-19 on young adults: evidence from hospitalisations in Brazil\n\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2021\n\n\nRaphael Guimarães, Daniel Vilela, Diego Xavier, Raphael Saldanha, Christovam Barcellos, Carlos Freitas, Margareth Portela\n\n\n\n\n\n\n  \n\n\n\n\nAdesão às medidas de restrição de contato físico e disseminação da COVID-19 no Brasil\n\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2020\n\n\nCelia Szwarcwald, Paulo Souza Junior, Deborah Malta, Marilisa Barros, Raphael Saldanha, Giseli Damascena, Luiz Azevedo, Margareth Lima, Dalia Romero, Ísis Machado, Crizian Gomes, André Werneck, Danilo Silva, Renata Gracie, Maria Pina\n\n\n\n\n\n\n  \n\n\n\n\nIs it time to talk about the end of social distancing? A joinpoint analysis of COVID-19 time series in Brazilian capitals\n\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2020\n\n\nRaphael Guimarães, Monica Magalhães, Diego Xavier, Raphael Saldanha, Rafael Catão\n\n\n\n\n\n\n  \n\n\n\n\nResurgence risk for malaria, and the characterization of a recent outbreak in an Amazonian border area between French Guiana and Brazil\n\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2020\n\n\nEmilie Mosnier, Isabelle Dusfour, Guillaume Lacour, Raphael Saldanha, Amandine Guidez, Margaret Gomes, Alice Sanna, Yanouk Epelboin, Johana Restrepo, Damien Davy, Magalie Demar, Félix Djossou, Maylis Douine, Vanessa Ardillon, Mathieu Nacher, Lise Musset, Emmanuel Roux\n\n\n\n\n\n\n  \n\n\n\n\nFatores associados ao letramento funcional em saúde de mulheres atendidas pela Estratégia de Saúde da Família\n\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2020\n\n\nAngélica Campos, Felipe Neves, Raphael Saldanha, Kristiane Duque, Maximiliano Guerra, Isabel Leite, Maria Teixeira\n\n\n\n\n\n\n  \n\n\n\n\nMicrodatasus: pacote para download e pré-processamento de microdados do Departamento de Informática do SUS (DATASUS)\n\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2019\n\n\nRaphael Saldanha, Ronaldo Bastos, Christovam Barcellos\n\n\n\n\n\n\n  \n\n\n\n\nEstudo de análise de rede do fluxo de pacientes de câncer de mama no Brasil entre 2014 e 2016\n\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2019\n\n\nRaphael Saldanha, Diego Xavier, Keila Carnavalli, Kátia Lerner, Christovam Barcellos\n\n\n\n\n\n\n  \n\n\n\n\nCrescimento do emprego industrial local no Brasil: o grau de especialização por intensidade tecnológica importa?\n\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2019\n\n\nEduardo Gonçalves, Raphael Saldanha, Eduardo Almeida, André Silva\n\n\n\n\n\n\n  \n\n\n\n\nContributing to Elimination of Cross-Border Malaria Through a Standardized Solution for Case Surveillance, Data Sharing, and Data Interpretation: Development of a Cross-Border Monitoring System\n\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2019\n\n\nRaphael Saldanha, Émilie Mosnier, Christovam Barcellos, Aurel Carbunar, Christophe Charron, Jean-Christophe Desconnets, Basma Guarmit, Margarete Gomes, Théophile Mandon, Anapaula Mendes, Paulo Peiter, Lise Musset, Alice Sanna, Benoît Van Gastel, Emmanuel Roux\n\n\n\n\n\n\n  \n\n\n\n\nAs Regiões de Saúde no Brasil segundo internações: método para apoio na regionalização de saúde\n\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2019\n\n\nDiego Xavier, Ricardo Oliveira, Christovam Barcellos, Raphael Saldanha, Walter Ramalho, Josué Laguardia, Francisco Viacava\n\n\n\n\n\n\n  \n\n\n\n\nWhat have we learned from Mariana? The importance of names, places and affections\n\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2019\n\n\nNadja Araújo, Keila Carnavalli, Nathalia Barbosa, Patricia Barcelos, Raphael Saldanha, Teresa Neves, Vinicius Klein, Maria Guimarães\n\n\n\n\n\n\n  \n\n\n\n\nBurden of disease in Brazil, 1990–2016: a systematic subnational analysis for the Global Burden of Disease Study 2016\n\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2018\n\n\nFatima Marinho et al.\n\n\n\n\n\n\n  \n\n\n\n\nProposta de um observatório epidemiológico do Sistema Único de Saúde\n\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2017\n\n\nRaphael Saldanha, Ronaldo Bastos, Maria Bustamante-Teixeira, Isabel Leite, Estela Campos\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "projects/pns.html",
    "href": "projects/pns.html",
    "title": "PNS",
    "section": "",
    "text": "PNS main webpage.\n\n\nThis project is a partnership between PCDaS and other researchers at Fiocruz and IBGE. The PNS is a national inquiry about the population health conditions with two editions: 2013 and 2019. Its results cover major aspects of populations’ health and involve special techniques for complex samples.\nI oversee the team at PCDaS responsible to create reproducible code notebooks about sample expansion and developing and maintain a website with project documentation and a data dashboard.\nProject website address: https://www.pns.icict.fiocruz.br\nThis work is supported by Brazilian Health Ministry.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/ouvsus.html",
    "href": "projects/ouvsus.html",
    "title": "OuvSUS",
    "section": "",
    "text": "Manifestações dashboard.\n\n\nA partnership between PCDaS, Instituto Aggeu Magalhães – Fiocruz Pernambuco, and the Brazilian Ministry of Health ombudsman. The project aims to collect, organize and present data about population inquiries and information requisitions.\nI oversee the team at PCDaS responsible for the ETL (extraction, transform and load) process and data dashboard.\nThe project website address: https://www.gov.br/saude/pt-br/canais-de-atendimento/ouvidoria-do-sus/ouvidoria-em-numeros/paineis-de-dados\nThis work is supported by Brazilian Health Ministry.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/monitoracovid19.html",
    "href": "projects/monitoracovid19.html",
    "title": "MonitoraCovid-19",
    "section": "",
    "text": "MonitoraCovid-19 dashboard.\n\n\nMonitoraCovid-19 project is an institutional response from Fiocruz to the Covid-19 pandemic.\nThe project started in March 2020, when the first cases of Covid-19 occurred in Brazil. Since then, we monitored the pandemic daily, unifying more than 10 data sources into a unique data dashboard with several graphs and maps.\nI am responsible to the ETL process and data dashboard. The project website was accessed more than 700,000 times by more than 300,000 users worldwide.\nWe published 25 technical notes and 12 brief texts about the pandemic, along with papers and a book chapter.\nThis work was supported by the Fiocruz Inova and received the ENAP prize.\nThe dashboard address: https://bigdata-covid19.icict.fiocruz.br\nInterview at Fantástico (Rede Globo, May 2020): https://g1.globo.com/fantastico/noticia/2020/05/10/com-medidas-mais-rigorosas-paises-vizinhos-ao-brasil-dao-exemplo-no-combate-a-covid-19.ghtml\nTalk at ICICT Centro de Estudos, with Atila Iamarino and Diego Xavier (August 19, 2022): https://www.youtube.com/watch?v=GeyPs9yMzSk&t=3867s\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/harmonize.html",
    "href": "projects/harmonize.html",
    "title": "Harmonize",
    "section": "",
    "text": "Harmonizing multi-scale spatiotemporal data for health in climate change hotspots.\nHarmonize is a project in partnership with the Health and Climate Observatory and several international partners, including the Barcelona Supercomputing Center (BSC).\nThe project’s objective is to collect, organize and analyze multi-scale spatiotemporal data for health in climate hotspots.\nI am working on this project to provide expert knowledge on Brazilian health data collection and analysis.\nThis work is supported by the Wellcome Trust grant number 224694/Z/21/Z.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/cidade-e-saude.html",
    "href": "projects/cidade-e-saude.html",
    "title": "Cidade & Saúde",
    "section": "",
    "text": "Cidade & Saúde main webpage.\n\n\n“Cidade & Saúde” is a self-funded Project that I started just after my master’s and before my Ph.D.\nThe project objective is to collect and aggregate health data at the municipality level and provide simple and visually compelling access with satellite images and graphs. The user is asked to type a city name and the system presents a webpage with the satellite image of that city and several socio-demographic and health information with graphs.\nThe satellite image is used to put the socio-demographic and health data in context, with graphs and indicators definitions covering demographic aspects, mortality, hospital admissions, health units, and health budget.\nThe project website is accessible by this address: https://cidadesaude.io. The project data is out of date, and waiting for financing.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/agua-saude.html",
    "href": "projects/agua-saude.html",
    "title": "Água & Saúde",
    "section": "",
    "text": "Água & Saúde main webpage.\n\n\nThe first project that I got involved at Fiocruz with the Climate and Health Observatory. It was a project in partnership with ANA (Agência Nacional das Águas).\nI was in charge to create a database of health and water indicators and a data dashboard. The project was fully developed with R, Shiny, and SQLite technologies.\nThe project has been discontinued.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/std_br_covid_rates.html",
    "href": "posts/std_br_covid_rates.html",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "",
    "text": "On this post, we will compute crude and age-adjusted COVID-19 mortality rates for Brazilian municipalities, from 2020 to 2022 per epidemiological weeks.\nWe will use the {tidyverse} and other packages that I will call later.\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/std_br_covid_rates.html#covid-19-mortality-data",
    "href": "posts/std_br_covid_rates.html#covid-19-mortality-data",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "COVID-19 mortality data",
    "text": "COVID-19 mortality data\nThe Brazilian official source of mortality data is a health information system called “Sistema de Informações de Mortalidade – SIM”. This system receives mortality data from the municipalities and states and consolidates it.\nThe SIM dataset is published yearly, with a year lag. This time is needed to consolidate all the data and perform checks. The SIM datasets of 2019, 2020, and 2021 are officially published and the 2022 dataset is published as “preliminary”, which means that modifications and updates are possible.\nThe datasets are publicly available on the OpenDataSUS website as CSV files. I downloaded the datasets from 2019 to 2023, as the 2023 may have some death records that occurred in 2022.\nThe code chunk below has the CSV column types specification to read these files with the {readr} package. The chunk is folded to save screen space ;-)\n\n\nCode\ndate_format &lt;- \"%d%m%Y\"\n\ncols_spec &lt;- cols(\n  ORIGEM = col_double(),\n  TIPOBITO = col_double(),\n  DTOBITO = col_date(format = date_format),\n  HORAOBITO = col_character(),\n  NATURAL = col_character(),\n  CODMUNNATU = col_double(),\n  DTNASC = col_date(format = date_format),\n  IDADE = col_double(),\n  SEXO = col_double(),\n  RACACOR = col_double(),\n  ESTCIV = col_double(),\n  ESC = col_double(),\n  ESC2010 = col_double(),\n  SERIESCFAL = col_double(),\n  OCUP = col_character(),\n  CODMUNRES = col_double(),\n  LOCOCOR = col_double(),\n  CODESTAB = col_character(),\n  ESTABDESCR = col_character(),\n  CODMUNOCOR = col_double(),\n  IDADEMAE = col_double(),\n  ESCMAE = col_double(),\n  ESCMAE2010 = col_double(),\n  SERIESCMAE = col_double(),\n  OCUPMAE = col_double(),\n  QTDFILVIVO = col_character(),\n  QTDFILMORT = col_character(),\n  GRAVIDEZ = col_double(),\n  SEMAGESTAC = col_double(),\n  GESTACAO = col_double(),\n  PARTO = col_double(),\n  OBITOPARTO = col_double(),\n  PESO = col_character(),\n  TPMORTEOCO = col_double(),\n  OBITOGRAV = col_double(),\n  OBITOPUERP = col_double(),\n  ASSISTMED = col_double(),\n  EXAME = col_character(),\n  CIRURGIA = col_character(),\n  NECROPSIA = col_double(),\n  LINHAA = col_character(),\n  LINHAB = col_character(),\n  LINHAC = col_character(),\n  LINHAD = col_character(),\n  LINHAII = col_character(),\n  CAUSABAS = col_character(),\n  CB_PRE = col_character(),\n  COMUNSVOIM = col_character(),\n  DTATESTADO = col_date(format = date_format),\n  CIRCOBITO = col_double(),\n  ACIDTRAB = col_double(),\n  FONTE = col_double(),\n  NUMEROLOTE = col_double(),\n  TPPOS = col_character(),\n  DTINVESTIG = col_date(format = date_format),\n  CAUSABAS_O = col_character(),\n  DTCADASTRO = col_date(format = date_format),\n  ATESTANTE = col_double(),\n  STCODIFICA = col_character(),\n  CODIFICADO = col_character(),\n  VERSAOSIST = col_number(),\n  VERSAOSCB = col_number(),\n  FONTEINV = col_double(),\n  DTRECEBIM = col_date(format = date_format),\n  ATESTADO = col_character(),\n  DTRECORIGA = col_date(format = date_format),\n  CAUSAMAT = col_character(),\n  ESCMAEAGR1 = col_character(),\n  ESCFALAGR1 = col_character(),\n  STDOEPIDEM = col_double(),\n  STDONOVA = col_double(),\n  DIFDATA = col_character(),\n  NUDIASOBCO = col_double(),\n  NUDIASOBIN = col_character(),\n  DTCADINV = col_date(format = date_format),\n  TPOBITOCOR = col_double(),\n  DTCONINV = col_date(format = date_format),\n  FONTES = col_character(),\n  TPRESGINFO = col_double(),\n  TPNIVELINV = col_character(),\n  NUDIASINF = col_character(),\n  DTCADINF = col_date(format = date_format),\n  MORTEPARTO = col_double(),\n  DTCONCASO = col_date(format = date_format),\n  FONTESINF = col_character(),\n  ALTCAUSA = col_double(),\n  CONTADOR = col_double()\n)\n\n\nThe code chunk bellow reads the CSV file with the column types specification from above.\n\nsim19 &lt;- readr::read_csv2(file = \"../../covidbr/Mortalidade_Geral_2019.csv\", col_types = cols_spec)\nsim20 &lt;- readr::read_csv2(file = \"../../covidbr/Mortalidade_Geral_2020.csv\", col_types = cols_spec)\nsim21 &lt;- readr::read_csv2(file = \"../../covidbr/Mortalidade_Geral_2021.csv\", col_types = cols_spec)\nsim22 &lt;- readr::read_csv2(file = \"../../covidbr/DO22OPEN.csv\", col_types = cols_spec)\nsim23 &lt;- readr::read_csv2(file = \"../../covidbr/DO23OPEN.csv\", col_types = cols_spec)\n\nAfter reading the files, let’s create one single data frame with the variables we will use.\n\n1covid &lt;- bind_rows(sim19, sim20, sim21, sim22, sim23) %&gt;%\n2  filter(CAUSABAS == \"B342\") %&gt;%\n3  filter(DTOBITO &gt;= as.Date(\"2020-01-01\") & DTOBITO &lt;= as.Date(\"2022-12-31\")) %&gt;%\n4  select(DTOBITO, DTNASC, CODMUNRES) %&gt;%\n5  na.omit()\n\n6rm(sim19, sim20, sim21, sim22, sim23, cols_spec, date_format)\n\n\n1\n\nBind the sim objects into a single data frame.\n\n2\n\nFilter the records where the basic cause of death is COVID-19 (ICD-10 code B342).\n\n3\n\nFilter the records keeping only the deaths that occurred between 2019 and 2022.\n\n4\n\nSelect the date of death (DTOBITO) and date of birth (DTNASC) to compute the age and the municipality code of residence (CODMUNRES).\n\n5\n\nOmit rows with missing data.\n\n6\n\nRemove the sim* objects as we will no longer need them.\n\n\n\n\nOur dataset has 702284 records.\n\nhead(covid, 10)\n\n# A tibble: 10 × 3\n   DTOBITO    DTNASC     CODMUNRES\n   &lt;date&gt;     &lt;date&gt;         &lt;dbl&gt;\n 1 2020-05-21 1942-08-10    120010\n 2 2020-05-27 1943-02-19    120010\n 3 2020-05-27 1975-01-14    120025\n 4 2020-05-05 1972-06-10    120040\n 5 2020-05-25 1939-10-04    120040\n 6 2020-05-25 1965-02-14    120040\n 7 2020-05-25 1946-06-17    120040\n 8 2020-05-30 1937-05-17    120080\n 9 2020-05-30 1959-06-08    120013\n10 2020-05-13 1982-08-22    120040\n\n\n\nAge groups\nNow we need to label the records into age groups.\n\ncovid &lt;- covid %&gt;%\n  mutate(\n1    age = year(as.period(interval(start = DTNASC, end = DTOBITO))),\n2    age_group = case_when(\n      age &lt;= 4 ~ \"From 0 to 4 years\",\n      age &gt;= 5 & age &lt;= 9 ~ \"From 5 to 9 years\",\n      age &gt;= 10 & age &lt;= 14 ~ \"From 10 to 14 years\",\n      age &gt;= 15 & age &lt;= 19 ~ \"From 15 to 19 years\",\n      age &gt;= 20 & age &lt;= 24 ~ \"From 20 to 24 years\",\n      age &gt;= 25 & age &lt;= 29 ~ \"From 25 to 29 years\",\n      age &gt;= 30 & age &lt;= 34 ~ \"From 30 to 34 years\",\n      age &gt;= 35 & age &lt;= 39 ~ \"From 35 to 39 years\",\n      age &gt;= 40 & age &lt;= 44 ~ \"From 40 to 44 years\",\n      age &gt;= 45 & age &lt;= 49 ~ \"From 45 to 49 years\",\n      age &gt;= 50 & age &lt;= 54 ~ \"From 50 to 54 years\",\n      age &gt;= 55 & age &lt;= 59 ~ \"From 55 to 59 years\",\n      age &gt;= 60 & age &lt;= 64 ~ \"From 60 to 64 years\",\n      age &gt;= 65 & age &lt;= 69 ~ \"From 65 to 69 years\",\n      age &gt;= 70 & age &lt;= 74 ~ \"From 70 to 74 years\",\n      age &gt;= 75 & age &lt;= 79 ~ \"From 75 to 79 years\",\n      age &gt;= 80 ~ \"From 80 years or more\"\n    ),\n3    age_group = fct_relevel(\n      age_group,\n      \"From 0 to 4 years\", \"From 5 to 9 years\",\n      \"From 10 to 14 years\", \"From 15 to 19 years\",\n      \"From 20 to 24 years\", \"From 25 to 29 years\",\n      \"From 30 to 34 years\", \"From 35 to 39 years\",\n      \"From 40 to 44 years\", \"From 45 to 49 years\",\n      \"From 50 to 54 years\", \"From 55 to 59 years\",\n      \"From 60 to 64 years\", \"From 65 to 69 years\",\n      \"From 70 to 74 years\", \"From 75 to 79 years\",\n      \"From 80 years or more\"\n    )\n  ) %&gt;%\n4  select(date = DTOBITO, code_muni = CODMUNRES, age_group)\n\n\n1\n\nCompute the age based on the date of birth and date of death. For this, I used some functions from the {lubridate} package.\n\n2\n\nLabel the age groups.\n\n3\n\nConvert age_group to an ordered factor variable.\n\n4\n\nSelect and rename the desired variables.\n\n\n\n\n\nhead(covid, 10)\n\n# A tibble: 10 × 3\n   date       code_muni age_group            \n   &lt;date&gt;         &lt;dbl&gt; &lt;fct&gt;                \n 1 2020-05-21    120010 From 75 to 79 years  \n 2 2020-05-27    120010 From 75 to 79 years  \n 3 2020-05-27    120025 From 45 to 49 years  \n 4 2020-05-05    120040 From 45 to 49 years  \n 5 2020-05-25    120040 From 80 years or more\n 6 2020-05-25    120040 From 55 to 59 years  \n 7 2020-05-25    120040 From 70 to 74 years  \n 8 2020-05-30    120080 From 80 years or more\n 9 2020-05-30    120013 From 60 to 64 years  \n10 2020-05-13    120040 From 35 to 39 years  \n\n\nLet’s take a look at the epidemiological curves per date and age group.\n\ncovid %&gt;%\n  group_by(date, age_group) %&gt;%\n  summarise(events = n()) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(x = date, y = events)) +\n  geom_line() +\n  facet_wrap(~age_group) +\n  theme_bw()\n\n\n\n\nIt is pretty clear that COVID-19 mortality incidence is related to age. Thus, to compare mortality rates of different regions, we need to compute age-adjusted rates.\n\n\nAggregate data\nLet’s aggregate our dataset by municipality of residence, epidemiological and epidemiological week.\n\ncovid_agg &lt;- covid %&gt;%\n1  group_by(code_muni, date, age_group) %&gt;%\n  summarise(events = n()) %&gt;%\n  ungroup() %&gt;%\n2  group_by(code_muni) %&gt;%\n  complete(\n    date = seq.Date(as.Date(\"2020-01-01\"), as.Date(\"2022-12-31\"), by = \"day\"),\n    age_group = unique(covid$age_group),\n    fill = list(events = 0)\n  ) %&gt;%\n  ungroup() %&gt;%\n3  mutate(\n    year = epiyear(date),\n    week = epiweek(date)\n  ) %&gt;%\n4  group_by(code_muni, year, week, age_group) %&gt;%\n  summarise(events = sum(events)) %&gt;%\n  ungroup()\n\n\n1\n\nFirst, we aggregate the COVID-19 per municipality of residence, age group and date. But this aggregation have some gaps on date and age groups, as there are no deaths at some specific dates and age groups.\n\n2\n\nWe can complete these gaps using the tidyr::complete, supplying the dates interval and age groups. We will fill the events variables with zero values.\n\n3\n\nWith the complete dataset, we compute the epidemiological year and week.\n\n4\n\nAnd aggregate by municipality code, year, week and age_group."
  },
  {
    "objectID": "posts/std_br_covid_rates.html#population-data",
    "href": "posts/std_br_covid_rates.html#population-data",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "Population data",
    "text": "Population data\nWe need to add the population data to compute the rates. Let’s prepare our population data using the brpop package.\n\nmun_pop &lt;- brpop::mun_pop() %&gt;%\n  filter(year %in% 2020:2022) %&gt;%\n  rename(population = pop) %&gt;%\n  filter(age_group != \"Total\") %&gt;%\n  rename(code_muni = mun)\n\nAs there is no population estimates for 2022 yet, we will repeat the population from 2021.\n\nmun_pop_2022 &lt;- mun_pop %&gt;%\n  filter(year == 2021) %&gt;%\n  mutate(year = 2022)\n\nmun_pop &lt;- bind_rows(mun_pop, mun_pop_2022)\nrm(mun_pop_2022)\n\nLet’s join this population data with the COVID-19 data.\n\ncovid_agg &lt;- right_join(covid_agg, mun_pop, by = c(\"code_muni\", \"year\", \"age_group\")) %&gt;% \n  pivot_longer(cols = c(\"events\", \"population\"))\n\nhead(covid_agg, 10)\n\n# A tibble: 10 × 6\n   code_muni  year  week age_group           name       value\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;      &lt;int&gt;\n 1    110000  2020     1 From 0 to 4 years   events         0\n 2    110000  2020     1 From 0 to 4 years   population     0\n 3    110000  2020     1 From 5 to 9 years   events         0\n 4    110000  2020     1 From 5 to 9 years   population     0\n 5    110000  2020     1 From 10 to 14 years events         0\n 6    110000  2020     1 From 10 to 14 years population     0\n 7    110000  2020     1 From 15 to 19 years events         0\n 8    110000  2020     1 From 15 to 19 years population     0\n 9    110000  2020     1 From 20 to 24 years events         0\n10    110000  2020     1 From 20 to 24 years population     0"
  },
  {
    "objectID": "posts/std_br_covid_rates.html#reference-population",
    "href": "posts/std_br_covid_rates.html#reference-population",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "Reference population",
    "text": "Reference population\nWe will use as reference population, the year of 2020.\n\npop_ref &lt;- mun_pop %&gt;%\n  filter(year == 2020) %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(population = sum(population)) %&gt;%\n  ungroup()\n\nprint(pop_ref)\n\n# A tibble: 17 × 2\n   age_group             population\n   &lt;chr&gt;                      &lt;int&gt;\n 1 From 0 to 4 years       14730300\n 2 From 10 to 14 years     14805480\n 3 From 15 to 19 years     15790890\n 4 From 20 to 24 years     17233273\n 5 From 25 to 29 years     16985859\n 6 From 30 to 34 years     17205414\n 7 From 35 to 39 years     17026565\n 8 From 40 to 44 years     15602995\n 9 From 45 to 49 years     13652508\n10 From 5 to 9 years       14650284\n11 From 50 to 54 years     12617802\n12 From 55 to 59 years     11257270\n13 From 60 to 64 years      9383724\n14 From 65 to 69 years      7349241\n15 From 70 to 74 years      5408657\n16 From 75 to 79 years      3614384\n17 From 80 years or more    4441046"
  },
  {
    "objectID": "posts/std_br_covid_rates.html#crude-and-adjusted-rates",
    "href": "posts/std_br_covid_rates.html#crude-and-adjusted-rates",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "Crude and adjusted rates",
    "text": "Crude and adjusted rates\nTo compute the crude and age-adjusted rates, we will use the {tidyrates} package.\n\nrates &lt;- tidyrates::rate_adj_direct(\n  .data = covid_agg, \n  .std = pop_ref, \n  .keys = c(\"code_muni\", \"year\", \"week\"), \n  .progress = FALSE\n) %&gt;%\n  mutate(\n    crude.rate = crude.rate * 100000,\n    adj.rate = adj.rate * 100000,\n    lci = lci * 100000,\n    uci = uci * 100000,\n  )\n\nThat’s it! Let’s take a look at the rates for Rio de Janeiro, RJ on 2022.\n\nrates %&gt;%\n  filter(code_muni == 330455) %&gt;%\n  filter(year == 2022)\n\n# A tibble: 52 × 7\n   code_muni  year  week crude.rate adj.rate   lci   uci\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1    330455  2022     1      0.251    0.175 0.101 0.297\n 2    330455  2022     2      1.17     0.839 0.662 1.06 \n 3    330455  2022     3      3.81     2.70  2.37  3.06 \n 4    330455  2022     4      5.58     3.96  3.57  4.40 \n 5    330455  2022     5      4.44     3.11  2.76  3.49 \n 6    330455  2022     6      2.83     2.00  1.72  2.32 \n 7    330455  2022     7      1.98     1.43  1.20  1.71 \n 8    330455  2022     8      0.989    0.682 0.528 0.880\n 9    330455  2022     9      0.398    0.283 0.185 0.428\n10    330455  2022    10      0.310    0.217 0.133 0.346\n# ℹ 42 more rows\n\n\nLet’s save the rates data frame as a parquet and CSV file.\n\narrow::write_parquet(x = rates, sink = \"../../covidbr/covid19_adj_rates.parquet\")\nwrite_csv2(x = rates, file = \"../../covidbr/covid19_adj_rates.csv\")\n\nThese files are available for download at Zenodo:"
  },
  {
    "objectID": "posts/std_br_covid_rates.html#mortality-rates-graph-for-capitals",
    "href": "posts/std_br_covid_rates.html#mortality-rates-graph-for-capitals",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "Mortality rates graph for capitals",
    "text": "Mortality rates graph for capitals\nThe graph bellow present the crude and adjusted rates at the Brazilian capitals.\n\ncapitals &lt;- geobr::read_capitals(as_sf = TRUE, showProgress = FALSE) %&gt;%\n  mutate(\n    code_muni = ifelse(code_muni == 2803203, 2800308, code_muni),\n    name_muni = ifelse(code_muni == 2800308, \"Aracaju\", name_muni)\n  ) %&gt;%\n  mutate(code_muni = as.numeric(substr(code_muni, 0, 6))) %&gt;%\n  select(-year) %&gt;%\n  sf::st_drop_geometry()\n\nrates_for_plot &lt;- rates %&gt;%\n  right_join(capitals, by = \"code_muni\") %&gt;%\n  mutate(week = paste0(year, \"-\", str_pad(week, 2, pad = \"0\"))) %&gt;%\n  select(week, name_muni, crude.rate, adj.rate) %&gt;%\n  pivot_longer(cols = c(\"crude.rate\", \"adj.rate\")) \n\nggplot() +\n  geom_line(data = rates_for_plot, aes(x = week, y = value, group = name, color = name)) +\n  facet_wrap(~name_muni) +\n  theme_bw() +\n  theme(\n    legend.position = \"bottom\", \n    legend.direction = \"horizontal\", \n    axis.text.x=element_blank(),\n    axis.ticks.x=element_blank()\n  ) +\n  labs(\n    title = \"Age standardized COVID-19 mortality rates for Brazilian capitals\", \n    x = \"Epi Week\", \n    y = \"Rate per 100,000 inhab.\", \n    color = NULL\n  )"
  },
  {
    "objectID": "posts/std_br_covid_rates.html#session-info",
    "href": "posts/std_br_covid_rates.html#session-info",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Paris\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.3    \n [5] purrr_1.0.2     readr_2.1.4     tidyr_1.3.0     tibble_3.2.1   \n [9] ggplot2_3.4.4   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4        xfun_0.41           htmlwidgets_1.6.2  \n [4] brpop_0.3.0         processx_3.8.2      RApiSerialize_0.1.2\n [7] callr_3.7.3         tzdb_0.4.0          vctrs_0.6.4        \n[10] tools_4.3.2         ps_1.7.5            generics_0.1.3     \n[13] curl_5.1.0          parallel_4.3.2      proxy_0.4-27       \n[16] fansi_1.0.5         pkgconfig_2.0.3     KernSmooth_2.23-22 \n[19] data.table_1.14.8   checkmate_2.3.0     assertthat_0.2.1   \n[22] RcppParallel_5.1.7  lifecycle_1.0.3     compiler_4.3.2     \n[25] farver_2.1.1        multidplyr_0.1.3    munsell_0.5.0      \n[28] qs_0.25.5           codetools_0.2-19    class_7.3-22       \n[31] htmltools_0.5.7     yaml_2.3.7          pillar_1.9.0       \n[34] crayon_1.5.2        epitools_0.5-10.1   classInt_0.4-10    \n[37] parallelly_1.36.0   tidyselect_1.2.0    digest_0.6.33      \n[40] stringi_1.7.12      future_1.33.0       sf_1.0-14          \n[43] listenv_0.9.0       labeling_0.4.3      arrow_13.0.0.1     \n[46] fastmap_1.1.1       grid_4.3.2          colorspace_2.1-0   \n[49] cli_3.6.1           magrittr_2.0.3      utf8_1.2.4         \n[52] e1071_1.7-13        withr_2.5.2         scales_1.2.1       \n[55] backports_1.4.1     bit64_4.0.5         timechange_0.2.0   \n[58] httr_1.4.7          rmarkdown_2.25      globals_0.16.2     \n[61] tidyrates_0.0.1     bit_4.0.5           hms_1.1.3          \n[64] stringfish_0.15.8   evaluate_0.23       knitr_1.45         \n[67] rlang_1.1.2         Rcpp_1.0.11         DBI_1.1.3          \n[70] glue_1.6.2          geobr_1.8.1         rstudioapi_0.15.0  \n[73] vroom_1.6.4         jsonlite_1.8.7      R6_2.5.1           \n[76] units_0.8-4"
  },
  {
    "objectID": "posts/some-tips-for-sqlite.html",
    "href": "posts/some-tips-for-sqlite.html",
    "title": "Some tips to work with SQLite database",
    "section": "",
    "text": "Databases are very useful for handling large-than-memory datasets, a common problem in Data Science. Several database engines work very well with R and Posit has a nice guide overview of them.\nSQLite is a very popular engine due its simplicity. You do not need to install a database server on your environment because SQLite stores the database in a simple single file that you can modify, copy, store at Google Drive etc.\nI have been using it for some time and collected some practical tips for some practical situations.\nFirst, lets have some data to use at the examples.\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(nycflights13)\n\nflights &lt;- flights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_date(year, month, day))\n\nglimpse(flights)\n\nRows: 336,776\nColumns: 6\n$ year      &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, …\n$ month     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ day       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ hour      &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, …\n$ minute    &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0, 0, …\n$ departure &lt;date&gt; 2013-01-01, 2013-01-01, 2013-01-01, 2013-01-01, 2013-01-01,…\nI specifically created a variable called departure to have a date type on our example dataset."
  },
  {
    "objectID": "posts/some-tips-for-sqlite.html#dates",
    "href": "posts/some-tips-for-sqlite.html#dates",
    "title": "Some tips to work with SQLite database",
    "section": "Dates",
    "text": "Dates\nNatively, SQLite databases does not handle dates and this may be difficult in the beginning. Let’s explore some options to handle dates with SQLite.\nFirst, we need to create a database in a temporary file using two packages: DBI and RSQLite.\n\nlibrary(DBI)\nlibrary(RSQLite)\n\ndatabase_file &lt;- tempfile()\nconn &lt;- dbConnect(RSQLite::SQLite(), database_file)\n\nObserve that the conn object is NOT the database, is just a connection instruction to the database stored in a file.\nLets write the flights tibble to the database.\n\ndbWriteTable(conn, name = \"flights_table\", value = flights)\n\nNow, let’s take a look how the tibble was stored.\n\ntbl(conn, \"flights_table\") %&gt;%\n  head() %&gt;% \n  collect()\n\n# A tibble: 6 × 6\n   year month   day  hour minute departure\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1  2013     1     1     5     15     15706\n2  2013     1     1     5     29     15706\n3  2013     1     1     5     40     15706\n4  2013     1     1     5     45     15706\n5  2013     1     1     6      0     15706\n6  2013     1     1     5     58     15706\n\n\nThe departure variable is no more a human-readable date, it is now a integer value in Unix time. That means: “the number of seconds since 1970-01-01 00:00:00 UTC”. Now very practical…\nThus, there as two options for this: you may convert your date variable to a string variable (as.character(...)) or use an argument called extended_types with the dbConnect command.\nIf you store the date variable as string, you will need to reconvert it to date wherever your collect data from your database, what is not very practical. Let’s see how the extented_types option works.\nFirst, let’s close our connection.\n\ndbDisconnect(conn)\n\nWe will modify our connection using this argument.\n\nconn &lt;- dbConnect(RSQLite::SQLite(), database_file, extended_types = TRUE)\n\nAnd now we will overwrite the data at the same table.\n\ndbWriteTable(conn, name = \"flights_table\", value = flights, overwrite = TRUE)\n\nLet’s see the result.\n\ntbl(conn, \"flights_table\") %&gt;% head() %&gt;% collect()\n\n# A tibble: 6 × 6\n   year month   day  hour minute departure \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;    \n1  2013     1     1     5     15 2013-01-01\n2  2013     1     1     5     29 2013-01-01\n3  2013     1     1     5     40 2013-01-01\n4  2013     1     1     5     45 2013-01-01\n5  2013     1     1     6      0 2013-01-01\n6  2013     1     1     5     58 2013-01-01\n\n\nVoilà! Now we can now see human-readable dates with a UNIX time variable."
  },
  {
    "objectID": "posts/some-tips-for-sqlite.html#parallel-write",
    "href": "posts/some-tips-for-sqlite.html#parallel-write",
    "title": "Some tips to work with SQLite database",
    "section": "Parallel write",
    "text": "Parallel write\nOne nice thing about databases is parallel writing. Imagine a function being executed in parallel and writing the results at the same database and even at the same table.\nThere are some nice tricks to allow it with SQLite. Basically, those are the options that I use.\n\nconn &lt;- DBI::dbConnect(RSQLite::SQLite(), database_file, extended_types = TRUE, synchronous = NULL)\ndbExecute(conn, \"PRAGMA busy_timeout = 5000\")\n\n[1] 0\n\ndbExecute(conn, \"BEGIN IMMEDIATE TRANSACTION\")\n\n[1] 0\n\ndbWriteTable(conn = conn, name = \"flights_table\", value = flights, append = TRUE)\ndbExecute(conn, \"COMMIT TRANSACTION\")\n\n[1] 0\n\ndbDisconnect(conn)\n\nThese options will secure that your connection waits other connections to conclude and immediately commit the transaction to the database."
  },
  {
    "objectID": "posts/some-tips-for-sqlite.html#delete-table",
    "href": "posts/some-tips-for-sqlite.html#delete-table",
    "title": "Some tips to work with SQLite database",
    "section": "Delete table",
    "text": "Delete table\nOne odd thing, after you delete a table in a database you need to vacuum it to get the free space.\nLets delete the file database and do some testing.\n\nunlink(database_file)\n\nWe will create the database with two equal tables.\n\nconn &lt;- dbConnect(RSQLite::SQLite(), database_file, extended_types = TRUE)\ndbWriteTable(conn = conn, name = \"flights_table_1\", value = flights)\ndbWriteTable(conn = conn, name = \"flights_table_2\", value = flights)\ndbDisconnect(conn)\n\nWhat’s is the size of the file?\n\nfs::file_size(database_file)\n\n13.4M\n\n\nNow, lets delete one of the tables.\n\nconn &lt;- dbConnect(RSQLite::SQLite(), database_file, extended_types = TRUE)\ndbRemoveTable(conn = conn, name = \"flights_table_1\")\ndbDisconnect(conn)\n\nfs::file_size(database_file)\n\n13.4M\n\n\nSame size… so, lets vacuum it!\n\nconn &lt;- dbConnect(RSQLite::SQLite(), database_file, extended_types = TRUE)\ndbExecute(conn, \"VACUUM;\")\n\n[1] 0\n\ndbDisconnect(conn)\n\nfs::file_size(database_file)\n\n6.69M\n\n\nAnd we have a smaller size!"
  },
  {
    "objectID": "posts/some-tips-for-sqlite.html#session-info",
    "href": "posts/some-tips-for-sqlite.html#session-info",
    "title": "Some tips to work with SQLite database",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.2.0 (2022-04-22)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS 14.0\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] RSQLite_2.3.1      DBI_1.1.3          nycflights13_1.0.2 lubridate_1.9.3   \n[5] dplyr_1.1.3       \n\nloaded via a namespace (and not attached):\n [1] pillar_1.9.0      compiler_4.2.0    dbplyr_2.3.4      tools_4.2.0      \n [5] digest_0.6.33     bit_4.0.5         jsonlite_1.8.7    evaluate_0.22    \n [9] memoise_2.0.1     lifecycle_1.0.3   tibble_3.2.1      timechange_0.2.0 \n[13] pkgconfig_2.0.3   rlang_1.1.1       cli_3.6.1         rstudioapi_0.15.0\n[17] yaml_2.3.7        xfun_0.40         fastmap_1.1.1     withr_2.5.1      \n[21] knitr_1.44        fs_1.6.3          hms_1.1.3         generics_0.1.3   \n[25] vctrs_0.6.4       htmlwidgets_1.6.2 bit64_4.0.5       tidyselect_1.2.0 \n[29] glue_1.6.2        R6_2.5.1          fansi_1.0.5       rmarkdown_2.25   \n[33] purrr_1.0.2       blob_1.2.4        magrittr_2.0.3    htmltools_0.5.6.1\n[37] utf8_1.2.3        cachem_1.0.8"
  },
  {
    "objectID": "posts/rates.html",
    "href": "posts/rates.html",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "",
    "text": "Rates allow the comparison between the number of counts between multiple classes with different population sizes. For example, 10 disease cases that occur in 100 population region have a different proportional importance than 10 cases in a 1,000 population region.\nIn epidemiology, those overall rates may be compared if both populations are similar. If the populations have different constitutions, the comparison between overall rates may be misleading as the disease may affect the age groups differently."
  },
  {
    "objectID": "posts/rates.html#introduction",
    "href": "posts/rates.html#introduction",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "",
    "text": "Rates allow the comparison between the number of counts between multiple classes with different population sizes. For example, 10 disease cases that occur in 100 population region have a different proportional importance than 10 cases in a 1,000 population region.\nIn epidemiology, those overall rates may be compared if both populations are similar. If the populations have different constitutions, the comparison between overall rates may be misleading as the disease may affect the age groups differently."
  },
  {
    "objectID": "posts/rates.html#available-packages",
    "href": "posts/rates.html#available-packages",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "Available packages",
    "text": "Available packages\nSome R packages, such as epitools and epiR, allow the computation of crude and adjusted rates. Those packages use as input, vectors or matrices containing the events count and population per age group.\nThe downside of them is that you need to use the rates function manually repeatedly times if you are going to compute rates for several regions."
  },
  {
    "objectID": "posts/rates.html#tidyrates-package",
    "href": "posts/rates.html#tidyrates-package",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "tidyrates package",
    "text": "tidyrates package\nI created the tidyrates to compute direct and indirect adjusted rates for several regions, years, and other keys that you might use. Internally, the package wraps the epitools functions and applies them to each group.\nhttps://rfsaldanha.github.io/tidyrates/"
  },
  {
    "objectID": "posts/rates.html#example-general-mortality-rates-in-brazilian-states-from-2010-to-2021",
    "href": "posts/rates.html#example-general-mortality-rates-in-brazilian-states-from-2010-to-2021",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "Example: General mortality rates in Brazilian states, from 2010 to 2021",
    "text": "Example: General mortality rates in Brazilian states, from 2010 to 2021\n\nMortality data\nThe dataset bellow presents the total number of deaths by any cause (general mortality) for the Brazilian states per age group, from 2010 to 2021. I collected the data from the PCDaS platform.\n\ngm_br_uf &lt;- readRDS(file = \"gm_br_uf.rds\")\n\nDT::datatable(gm_br_uf)\n\n\n\n\n\n\n\n\nPopulation data\nTo compute rates, we will need the state population size per age group for each year. The brpop package present estimates for this. We just need to do some adaptations.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(brpop)\n\n1pop_uf &lt;- uf_pop() %&gt;%\n2  filter(year %in% 2010:2021) %&gt;%\n3  rename(population = pop) %&gt;%\n4  filter(age_group != \"Total\") %&gt;%\n5  mutate(year = as.character(year))\n\n\n1\n\nGet population table from brpop package.\n\n2\n\nFilter the desired years\n\n3\n\nRename the population variable\n\n4\n\nRemove population totals, keeping only the population per age group\n\n5\n\nChange year variable from numeric to character.\n\n\n\n\n\nDT::datatable(pop_uf)\n\n\n\n\n\n\n\n\nReference population\nTo compute standardized rates, we need a reference population. We may use the SEER reference population (which is a corrected version from the WHO reference population) that is present in the tidyrates package. We need to use the same age group labels and also merge the population from 80 years or more to make it compatible with our data.\n\nseer2 &lt;- tidyrates::seer_std_pop %&gt;%\n  mutate(age_group = case_when(\n    age_group == \"0-4\" ~ \"From 0 to 4 years\",\n    age_group == \"5-9\" ~ \"From 5 to 9 years\",\n    age_group == \"10-14\" ~ \"From 10 to 14 years\",\n    age_group == \"15-19\" ~ \"From 15 to 19 years\",\n    age_group == \"20-24\" ~ \"From 20 to 24 years\",\n    age_group == \"25-29\" ~ \"From 25 to 29 years\",\n    age_group == \"30-34\" ~ \"From 30 to 34 years\",\n    age_group == \"35-39\" ~ \"From 35 to 39 years\",\n    age_group == \"40-44\" ~ \"From 40 to 44 years\",\n    age_group == \"45-49\" ~ \"From 45 to 49 years\",\n    age_group == \"50-54\" ~ \"From 50 to 54 years\",\n    age_group == \"55-59\" ~ \"From 55 to 59 years\",\n    age_group == \"60-64\" ~ \"From 60 to 64 years\",\n    age_group == \"65-69\" ~ \"From 65 to 69 years\",\n    age_group == \"70-74\" ~ \"From 70 to 74 years\",\n    age_group == \"75-79\" ~ \"From 75 to 79 years\",\n    age_group == \"80-84\" ~ \"From 80 years or more\",\n    age_group == \"85-89\" ~ \"From 80 years or more\",\n    age_group == \"90-94\" ~ \"From 80 years or more\",\n    age_group == \"95-99\" ~ \"From 80 years or more\",\n    age_group == \"100+\" ~ \"From 80 years or more\",\n    .default = age_group\n  )) %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(population = sum(population)) %&gt;%\n  ungroup()\n\n\nDT::datatable(seer2)\n\n\n\n\n\n\n\n\nCrude and direct adjusted rates\nNow, we can join the mortality dataset with the population dataset by uf, year, and age groups.\n\ngm_pop &lt;- left_join(gm_br_uf, pop_uf, by = c(\"uf\", \"year\", \"age_group\")) %&gt;%\n  pivot_longer(cols = c(\"events\", \"population\"))\n\nDT::datatable(gm_pop)\n\n\n\n\n\n\nWith the data ready, we can compute the direct adjusted rates with the tidyrates package for all UFs and years.\n\nlibrary(tidyrates)\n\nrates &lt;- rate_adj_direct(.data = gm_pop, .std = seer2, .keys = c(\"year\", \"uf\"))\n\nDT::datatable(rates)\n\n\n\n\n\n\n\n\nPlot\nTo make a plot, let’s do some modifications and pivot the data.\n\nlibrary(ggplot2)\nlibrary(geofacet)\n\nrates_for_plot &lt;- rates %&gt;%\n  mutate(year = as.numeric(year)) %&gt;%\n  pivot_longer(cols = c(\"crude.rate\", \"adj.rate\", \"lci\", \"uci\")) %&gt;%\n  filter(name %in% c(\"crude.rate\", \"adj.rate\")) %&gt;%\n  mutate(value = value * 100000)\n\nci_for_plot &lt;- rates %&gt;%\n  mutate(year = as.numeric(year)) %&gt;%\n  select(year, uf, lci, uci) %&gt;%\n  mutate(\n    lci = lci * 100000,\n    uci = uci * 100000\n  )\n\nbr_grid &lt;- br_states_grid1 %&gt;%\n  mutate(code_num = case_when(\n    code == \"RO\" ~ 11,\n    code == \"AC\" ~ 12,\n    code == \"AM\" ~ 13,\n    code == \"RR\" ~ 14,\n    code == \"PA\" ~ 15,\n    code == \"AP\" ~ 16,\n    code == \"TO\" ~ 17,\n    code == \"MA\" ~ 21,\n    code == \"PI\" ~ 22,\n    code == \"CE\" ~ 23,\n    code == \"RN\" ~ 24,\n    code == \"PB\" ~ 25,\n    code == \"PE\" ~ 26,\n    code == \"AL\" ~ 27,\n    code == \"SE\" ~ 28,\n    code == \"BA\" ~ 29,\n    code == \"MG\" ~ 31,\n    code == \"ES\" ~ 32,\n    code == \"RJ\" ~ 33,\n    code == \"SP\" ~ 35,\n    code == \"PR\" ~ 41,\n    code == \"SC\" ~ 42,\n    code == \"RS\" ~ 43,\n    code == \"MS\" ~ 50,\n    code == \"MT\" ~ 51,\n    code == \"GO\" ~ 52,\n    code == \"DF\" ~ 53,\n  ))\n\n\nggplot(data = rates_for_plot) +\n  geom_line(aes(x = year, y = value, color = name)) +\n  geom_ribbon(data = ci_for_plot, aes(x = year, ymin = lci, ymax = uci), alpha=0.3, fill = \"lightpink\", color = \"pink\") +\n  facet_geo(~uf, grid = br_grid, label = \"name\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\", legend.direction = \"horizontal\") +\n  labs(color = \"Rate\", x = \"Year\", y = \"Rate per 100,000 inhab.\")"
  },
  {
    "objectID": "posts/rates.html#session-info",
    "href": "posts/rates.html#session-info",
    "title": "Crude and adjusted rates in a tidy way",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Paris\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] geofacet_0.2.0  ggplot2_3.4.4   tidyrates_0.0.1 brpop_0.3.0    \n[5] tidyr_1.3.0     dplyr_1.1.3    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4        xfun_0.41           bslib_0.5.1        \n [4] htmlwidgets_1.6.2   ggrepel_0.9.4       processx_3.8.2     \n [7] lattice_0.22-5      RApiSerialize_0.1.2 callr_3.7.3        \n[10] vctrs_0.6.4         tools_4.3.2         crosstalk_1.2.0    \n[13] ps_1.7.5            generics_0.1.3      parallel_4.3.2     \n[16] tibble_3.2.1        proxy_0.4-27        fansi_1.0.5        \n[19] pkgconfig_2.0.3     KernSmooth_2.23-22  checkmate_2.3.0    \n[22] RcppParallel_5.1.7  lifecycle_1.0.3     farver_2.1.1       \n[25] compiler_4.3.2      multidplyr_0.1.3    munsell_0.5.0      \n[28] qs_0.25.5           codetools_0.2-19    imguR_1.0.3        \n[31] htmltools_0.5.7     class_7.3-22        sass_0.4.7         \n[34] yaml_2.3.7          pillar_1.9.0        jquerylib_0.1.4    \n[37] ellipsis_0.3.2      epitools_0.5-10.1   classInt_0.4-10    \n[40] DT_0.30             cachem_1.0.8        parallelly_1.36.0  \n[43] tidyselect_1.2.0    digest_0.6.33       future_1.33.0      \n[46] sf_1.0-14           purrr_1.0.2         listenv_0.9.0      \n[49] labeling_0.4.3      forcats_1.0.0       rnaturalearth_0.3.4\n[52] geogrid_0.1.2       fastmap_1.1.1       grid_4.3.2         \n[55] colorspace_2.1-0    cli_3.6.1           magrittr_2.0.3     \n[58] utf8_1.2.4          e1071_1.7-13        withr_2.5.2        \n[61] scales_1.2.1        backports_1.4.1     sp_2.1-1           \n[64] httr_1.4.7          rmarkdown_2.25      jpeg_0.1-10        \n[67] globals_0.16.2      gridExtra_2.3       png_0.1-8          \n[70] stringfish_0.15.8   evaluate_0.23       knitr_1.45         \n[73] rlang_1.1.2         Rcpp_1.0.11         glue_1.6.2         \n[76] DBI_1.1.3           rstudioapi_0.15.0   jsonlite_1.8.7     \n[79] R6_2.5.1            units_0.8-4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Raphael Saldanha",
    "section": "",
    "text": "Postdoctoral researcher at Inria and LNCC, research assistant at Fiocruz.\nHealth geographer and health data scientist. Undergraduate in Geography, specialization in Statistics, master’s in Public Health, and Ph.D. in Health Information.\nBrazilian from Nova Friburgo (RJ), lived for several years on Minas Gerais and Rio de Janeiro. Currently based on Montpellier, France.\nLoves to code and crunch huge health and climate datasets with R.\n\n\n Back to top"
  },
  {
    "objectID": "data-projects/std_br_covid_rates_data.html",
    "href": "data-projects/std_br_covid_rates_data.html",
    "title": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities",
    "section": "",
    "text": "This dataset present crude and age-adjusted COVID-19 mortality rates for Brazilian municipalities, from 2020 to 2022 per epidemiological weeks.\nMore details about the methodology are available at this blog post.\nDownload:\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data-projects/brazil-climate-zonal-indicators.html#introduction",
    "href": "data-projects/brazil-climate-zonal-indicators.html#introduction",
    "title": "Zonal statististics of climate indicators for Brazilian municipalities",
    "section": "Introduction",
    "text": "Introduction\nClimate indicators are used on several statistical models for many research areas and are specially important for modelling Climate Sensitive Diseases (CSD) incidence. Those models usually adopts a lattice structure, where its data is aggregated at administrative boundaries (e.g. disease incidence), but climate indicators are usually presented in a continuous regular grid format.\nTo make climate indicators compatible with lattice structures, zonal statistics may be adopted. Zonal statistics are descriptive statistics calculated using a set of cells that spatially intersects a given spatial boundary. For each boundary in a map, statistics like average, maximum value, minimum value, standard deviation, and sum are obtained to represent the cell’s values that intersect the boundary.\nI created some zonal statistics of climate indicators datasets for Brazilian municipalities from some climate data products and a R package called brclimr to retrieve this data."
  },
  {
    "objectID": "data-projects/brazil-climate-zonal-indicators.html#zonal-br-dwgd",
    "href": "data-projects/brazil-climate-zonal-indicators.html#zonal-br-dwgd",
    "title": "Zonal statististics of climate indicators for Brazilian municipalities",
    "section": "Zonal BR-DWGD",
    "text": "Zonal BR-DWGD\n\n\n\n\n\nThe BR-DWGD dataset (Xavier et al. 2022) presents daily meteorological data interpolated to a grid with 0.1° × 0.1° of spatial resolution for the Brazilian territory, with daily data from January 1, 1961, to July 31, 2020. It used data from 1,252 weather stations and 11,473 rain gauges in its interpolation methods, cross-validated to the selection of the best method for each weather indicator.\nThe following weather indicators are available from the BR-DWGD study: precipitation (mm), minimum temperature (°C), maximum temperature (°C), solar radiation (MJ⋅m−2 ), wind speed at 2m height (m⋅s−1) and relative humidity (%).\nThe following zonal statistics were computed.\n\nbrclimr::product_info(product = \"brdwgd\")\n\n&lt;list&gt;\n├─tmax: &lt;list&gt;\n│ ├─name: \"Maximum temperature\"\n│ ├─unit: \"Degree Celsius\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"Tmax_min\"\n│   ├─max: \"Tmax_max\"\n│   ├─mean: \"Tmax_mean\"\n│   └─sd: \"Tmax_sd\"\n├─tmin: &lt;list&gt;\n│ ├─name: \"Minimum temperature\"\n│ ├─unit: \"Degree Celsius\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"Tmin_min\"\n│   ├─max: \"Tmin_max\"\n│   ├─mean: \"Tmin_mean\"\n│   └─sd: \"Tmin_sd\"\n├─pr: &lt;list&gt;\n│ ├─name: \"Precipitation\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"pr_min\"\n│   ├─max: \"pr_max\"\n│   ├─mean: \"pr_mean\"\n│   ├─sd: \"pr_sd\"\n│   └─sum: \"pr_sum\"\n├─eto: &lt;list&gt;\n│ ├─name: \"Evapotranspiration\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"ETo_min\"\n│   ├─max: \"ETo_max\"\n│   ├─mean: \"ETo_mean\"\n│   ├─sd: \"ETo_sd\"\n│   └─sum: \"ETo_sd\"\n├─rh: &lt;list&gt;\n│ ├─name: \"Relative humidity\"\n│ ├─unit: \"Percentage\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"RH_min\"\n│   ├─max: \"RH_max\"\n│   ├─mean: \"RH_mean\"\n│   └─sd: \"RH_sd\"\n├─rs: &lt;list&gt;\n│ ├─name: \"Solar radiation\"\n│ ├─unit: \"MJ/m2\"\n│ ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"Rs_min\"\n│   ├─max: \"Rs_max\"\n│   ├─mean: \"Rs_mean\"\n│   └─sd: \"Rs_sd\"\n└─u2: &lt;list&gt;\n  ├─name: \"Wind speed\"\n  ├─unit: \"m/2\"\n  ├─date_range: \"Daily, 1961-01-01 to 2020-07-31\"\n  └─stats: &lt;list&gt;\n    ├─min: \"u2_min\"\n    ├─max: \"u2_max\"\n    ├─mean: \"u2_mean\"\n    └─sd: \"u2_sd\"\n\n\nThe results are availabe as parquet files, available at Zenodo."
  },
  {
    "objectID": "data-projects/brazil-climate-zonal-indicators.html#zonal-terraclimate",
    "href": "data-projects/brazil-climate-zonal-indicators.html#zonal-terraclimate",
    "title": "Zonal statististics of climate indicators for Brazilian municipalities",
    "section": "Zonal TerraClimate",
    "text": "Zonal TerraClimate\n\n\n\n\n\nThe TerraClimate (Abatzoglou et al. 2018) dataset presents monthly meteorological data interpolated to a grid with 0.04° × 0.04° (1/24th degree) of spatial resolution with world cover, with monthly data from January, 1958, to December, 2021.\nThe following weather indicators are available from the TerraClimate study: Actual Evapotranspiration (mm), Climate Water Deficit (mm), Potential evapotranspiration(mm), Precipitation (mm), Runoff (mm), Soil Moisture (mm), Downward surface shortwave radiation (W/m2), Snow water equivalent (mm), Minimum temperature (°C), Maximum temperature (°C), Vapor pressure (kPa), Wind speed (m/s), Vapor Pressure Deficit (kpa) and Palmer Drought Severity Index.\nThe following zonal statistics were computed.\n\nbrclimr::product_info(product = \"terraclimate\")\n\n&lt;list&gt;\n├─tmax: &lt;list&gt;\n│ ├─name: \"Maximum temperature\"\n│ ├─detail: \"Average for month\"\n│ ├─unit: \"Degree Celsius\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"tmax_min\"\n│   ├─max: \"tmax_max\"\n│   ├─mean: \"tmax_mean\"\n│   └─sd: \"tmax_sd\"\n├─tmin: &lt;list&gt;\n│ ├─name: \"Minimum temperature\"\n│ ├─detail: \"Average for month\"\n│ ├─unit: \"Degree Celsius\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"tmin_min\"\n│   ├─max: \"tmin_max\"\n│   ├─mean: \"tmin_mean\"\n│   └─sd: \"tmin_sd\"\n├─ppt: &lt;list&gt;\n│ ├─name: \"Precipitation\"\n│ ├─detail: \"Monthly total\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"ppt_min\"\n│   ├─max: \"ppt_max\"\n│   ├─mean: \"ppt_mean\"\n│   ├─sd: \"ppt_sd\"\n│   └─sum: \"ppt_sum\"\n├─aet: &lt;list&gt;\n│ ├─name: \"Actual Evapotranspiration\"\n│ ├─detail: \"Monthly total\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"aet_min\"\n│   ├─max: \"aet_max\"\n│   ├─mean: \"aet_mean\"\n│   ├─sd: \"aet_sd\"\n│   └─sum: \"aet_sum\"\n├─def: &lt;list&gt;\n│ ├─name: \"Climate Water Deficit\"\n│ ├─detail: \"Monthly total\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"def_min\"\n│   ├─max: \"def_max\"\n│   ├─mean: \"def_mean\"\n│   ├─sd: \"def_sd\"\n│   └─sum: \"def_sum\"\n├─pdsi: &lt;list&gt;\n│ ├─name: \"Palmer Drought Severity Index\"\n│ ├─detail: \"At end of month\"\n│ ├─unit: \"unitless\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"PDSI_min\"\n│   ├─max: \"PDSI_max\"\n│   ├─mean: \"PDSI_mean\"\n│   └─sd: \"PDSI_sd\"\n├─pet: &lt;list&gt;\n│ ├─name: \"Potential evapotranspiration\"\n│ ├─detail: \"Monthly total\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"pet_min\"\n│   ├─max: \"pet_max\"\n│   ├─mean: \"pet_mean\"\n│   ├─sd: \"pet_sd\"\n│   └─sum: \"pet_sum\"\n├─q: &lt;list&gt;\n│ ├─name: \"Runoff\"\n│ ├─detail: \"Monthly total\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"q_min\"\n│   ├─max: \"q_max\"\n│   ├─mean: \"q_mean\"\n│   ├─sd: \"q_sd\"\n│   └─sum: \"q_sum\"\n├─soil: &lt;list&gt;\n│ ├─name: \"Soil Moisture\"\n│ ├─detail: \"Total column, at end of month\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"soil_min\"\n│   ├─max: \"soil_max\"\n│   ├─mean: \"soil_mean\"\n│   ├─sd: \"soil_sd\"\n│   └─sum: \"soil_sum\"\n├─srad: &lt;list&gt;\n│ ├─name: \"Downward surface shortwave radia...\"\n│ ├─unit: \"W/m2\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"srad_min\"\n│   ├─max: \"srad_max\"\n│   ├─mean: \"srad_mean\"\n│   ├─sd: \"srad_sd\"\n│   └─sum: \"srad_sum\"\n├─swe: &lt;list&gt;\n│ ├─name: \"Snow water equivalent\"\n│ ├─detail: \"At end of month\"\n│ ├─unit: \"mm\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"swe_min\"\n│   ├─max: \"swe_max\"\n│   ├─mean: \"swe_mean\"\n│   ├─sd: \"swe_sd\"\n│   └─sum: \"swe_sum\"\n├─vap: &lt;list&gt;\n│ ├─name: \"Vapor pressure\"\n│ ├─detail: \"Average for month\"\n│ ├─unit: \"kPa\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"vap_min\"\n│   ├─max: \"vap_max\"\n│   ├─mean: \"vap_mean\"\n│   └─sd: \"vap_sd\"\n├─vpd: &lt;list&gt;\n│ ├─name: \"Vapor Pressure Deficit\"\n│ ├─detail: \"Average for month\"\n│ ├─unit: \"kPa\"\n│ ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n│ └─stats: &lt;list&gt;\n│   ├─min: \"vpd_min\"\n│   ├─max: \"vpd_max\"\n│   ├─mean: \"vpd_mean\"\n│   └─sd: \"vpd_sd\"\n└─ws: &lt;list&gt;\n  ├─name: \"Wind speed\"\n  ├─detail: \"Average for month\"\n  ├─unit: \"m/s\"\n  ├─date_range: \"Monthly, 1958-01 to 2021-12\"\n  └─stats: &lt;list&gt;\n    ├─min: \"ws_min\"\n    ├─max: \"ws_max\"\n    ├─mean: \"ws_mean\"\n    └─sd: \"ws_sd\"\n\n\nThe results are availabe as parquet files, available at Zenodo."
  },
  {
    "objectID": "code.html#selected-repos",
    "href": "code.html#selected-repos",
    "title": "Packages & Code",
    "section": "Selected repos",
    "text": "Selected repos"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities\n\n\n\n\n\n\n\ncovid19\n\n\ntidyrates\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2023\n\n\n\n\n\n\n  \n\n\n\n\nCounting consecutive sequences of events: run length encoding and warm spell occurence example\n\n\n\n\n\n\n\nrle\n\n\nwarm spell\n\n\nsequences\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\n\n\n\n\n  \n\n\n\n\nCrude and adjusted rates in a tidy way\n\n\n\n\n\n\n\nrates\n\n\nepidemiology\n\n\ntidyrates\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nQuery remote parquet files with DuckDB\n\n\n\n\n\n\n\ndatabase\n\n\nduckdb\n\n\nparquet\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nSQLite database conversion to DuckDB and Parquet files\n\n\n\n\n\n\n\ndatabase\n\n\nsqlite\n\n\nduckdb\n\n\nparquet\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nSome tips to work with SQLite database\n\n\n\n\n\n\n\ndatabase\n\n\nsqlite\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Full name: Raphael de Freitas Saldanha\nDate of birth: April 18, 1985\nLanguages: Portuguese, English"
  },
  {
    "objectID": "cv.html#general-information",
    "href": "cv.html#general-information",
    "title": "CV",
    "section": "",
    "text": "Full name: Raphael de Freitas Saldanha\nDate of birth: April 18, 1985\nLanguages: Portuguese, English"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "CV",
    "section": "Education",
    "text": "Education\n\n2022 - current. Postdoc at Inria and LNCC. Artificial intelligence applications on public health.\n2017 - 2021. PhD at Fiocruz, PPGICS. Information and Communication in Health.\n2015 - 2017. Graduate Degree (Master) at UFJF - PPGSC. Public Health.\n2008 - 2009. Specialization at UFJF. Computational Statistical Methods\n2003 - 2007. Undergraduate Degree at UFJF - ICHL-DG. Geography."
  },
  {
    "objectID": "cv.html#academic-interests",
    "href": "cv.html#academic-interests",
    "title": "CV",
    "section": "Academic interests",
    "text": "Academic interests\n\nData science\n\nR\nShiny apps\nQuarto\nPlotly\nPython\nJupyter Hub\nduckdb, SQLite\nElasticSearch\nKibana\n\n\n\nGIS\n\nQGIS\nESRI ArcGIS\nGeoserver\n\n\n\nOther\n\nGephi\nLaTeX\nLinux\nMacOS"
  },
  {
    "objectID": "cv.html#work-and-teaching-experience",
    "href": "cv.html#work-and-teaching-experience",
    "title": "CV",
    "section": "Work and teaching experience",
    "text": "Work and teaching experience\n\n2017 - current. Research assistant at Fiocruz, ICICT, PCDaS.\n2017 - current. Research assistant at Fiocruz, ICICT, Observatório de Clima e Saúde.\n2021 - 2022 Research assistant at Fiocruz, IOC, Lathema Lab (ArboAlvo).\n2017 - 2018 Research assistant at IRD, Maison de la Télédétection (Montpellier, FR).\n2017 - current. Workshop teacher of R.\n2017 - current. Workshop teacher of Introduction to Spatial Econometry with R.\n2013 Teaching Assistant, Scientific Methodology at UFJF, CRITT.\n2023 Distance learning supervisor at Unibanco Institute.\n2005 - 2016 GIS and statistics analyst at Plangeo.\n2012 Approved for substitute teacher position of Thematic Cartograph.\n2012 Distance learning supervisor of Statistics, course of Public Management.\n2011 Distance learning tutor for Business Statistics (Curso de Administração Pública à Distância – PNAP), UFJF.\n2010 Teacher of Technologies for Environmental Planning, FAFISM."
  },
  {
    "objectID": "cv.html#additional-training",
    "href": "cv.html#additional-training",
    "title": "CV",
    "section": "Additional training",
    "text": "Additional training\n\n2022 Public Health Disparities Geocoding Project 2.0. Harvard School of Public Health\n2022 Developing the SIR Model. Imperial College (Coursera)\n2022 Algoritmos e Modelos de Programação para Big Data. Laboratório Nacional de Computação Científica\n2022 Machine Learning, Curso-R.\n2022 R Deploy, Curso-R.\n2021 QBA/On-line - Sensibilização em Gestão da Qualidade, Biossegurança e Ambiente, Fiocruz.\n2020 Comunicação, Mídia e Saúde em Contexto de Emergências Sanitárias, UFAL.\n2018 Anthropological and Historical Approaches of Visualising Epidemics, COC, Fiocruz.\n2018 Information Visualization, Foundations and Applied Perception, NYU Tandon School of Engineering (Coursera).\n2017 Practical Machine Learning, Johns Hopkins University (Coursera).\n2016 Harvard - Brazil Collaborative Public Health Course, Harvard School of Public Health.\n2015 Introduction to Big Data, University of California, San Diego (Coursera).\n2011 Geoestatística com o uso do R, UFJF.\n2007 Workshop em modelagem em estudos longitudinais, UFJF.\n2007 Geomarketing - Conceitos e aplicações, Centro Universitário Senac.\n2004 Geografia e movimentos sociais, A América Latina, AGB.\n2003 Introdução à Gestão Ambiental Urbana, UFJF.\n2003 Flash Mx, CRITT, UFJF."
  },
  {
    "objectID": "cv.html#hobbies",
    "href": "cv.html#hobbies",
    "title": "CV",
    "section": "Hobbies",
    "text": "Hobbies\n\nCycling\nWood working"
  },
  {
    "objectID": "data-projects/era5land-daily-latin-america.html",
    "href": "data-projects/era5land-daily-latin-america.html",
    "title": "ERA5-Land selected indicators daily aggregates for Latin America",
    "section": "",
    "text": "Maximum temperature (k)"
  },
  {
    "objectID": "data-projects/era5land-daily-latin-america.html#introduction",
    "href": "data-projects/era5land-daily-latin-america.html#introduction",
    "title": "ERA5-Land selected indicators daily aggregates for Latin America",
    "section": "Introduction",
    "text": "Introduction\nThe ERA5-Land reanalysis from The Copernicus Programme is an incredible source of climate data with global coverage of land areas from 1950 to the present, at 10km spatial resolution. Its original data is at hourly interval, and monthly aggregates are also available at the Copernicus Data Store (CDS).\nFor some applications like Climate-Sensitive Diseases (CSD) modelling, the hourly interval may be too much detailed, but the monthly aggregation is too coarse.\nFor this reason, I created daily aggregates from some ERA5-Land indicators for the Latin America region."
  },
  {
    "objectID": "data-projects/era5land-daily-latin-america.html#methodology",
    "href": "data-projects/era5land-daily-latin-america.html#methodology",
    "title": "ERA5-Land selected indicators daily aggregates for Latin America",
    "section": "Methodology",
    "text": "Methodology\nI developed an R script using the KrigR package (Kusch and Davy 2022). The script downloads a set of indicators, starting on 1950, for a geographical bounding box covering the Latin America region (coordinates -118.47,-34.1,-56.65, 33.28), and aggregates the data from hourly to daily, saving its results as NetCDF files. Each resulting file covers a year’s month and presents data layers for each day of the respective month.\nThe table bellow contains the time aggregation functions applied to each climate indicator.\n\n\n\nIndicator\nDaily aggregation function\n\n\n\n\n2m temperature\nmean, max, min\n\n\n2m dewpoint temperature\nmean\n\n\nu component of wind\nmean\n\n\nv component of wind\nmean\n\n\nsurface pressure\nmean\n\n\ntotal precipitation\nsum"
  },
  {
    "objectID": "data-projects/era5land-daily-latin-america.html#data",
    "href": "data-projects/era5land-daily-latin-america.html#data",
    "title": "ERA5-Land selected indicators daily aggregates for Latin America",
    "section": "Data",
    "text": "Data\nThe resulting NetCDF files are available for download at Zenodo.\n\n\n\nYear\nZenodo deposit\n\n\n\n\n1950\n\n\n\n1951\n\n\n\n1952\n\n\n\n1953\n\n\n\n1954\n\n\n\n1955\n\n\n\n1956\n\n\n\n1957\n\n\n\n1958\n\n\n\n1959\n\n\n\n1960\n\n\n\n1961\n\n\n\n1962\n\n\n\n1963\n\n\n\n1964\n\n\n\n1965\n\n\n\n1966\n\n\n\n1967\n\n\n\n1968\n\n\n\n1969\n\n\n\n1970\n\n\n\n1971\n\n\n\n1972\n\n\n\n1973\n\n\n\n1974\n\n\n\n1975\n\n\n\n1976\n\n\n\n1977\n\n\n\n1978\n\n\n\n1979\n\n\n\n1980\n\n\n\n1981\n\n\n\n1982\n\n\n\n1983\n\n\n\n1984\n\n\n\n1985\n\n\n\n1986\n\n\n\n1987\n\n\n\n1988\n\n\n\n1989\n\n\n\n1990\n\n\n\n1991\n\n\n\n1992\n\n\n\n1993\n\n\n\n1994\n\n\n\n1995\n\n\n\n1996\n\n\n\n1997\n\n\n\n1998\n\n\n\n1999\n\n\n\n2000\n\n\n\n2001\n\n\n\n2002\n\n\n\n2003\n\n\n\n2004\n\n\n\n2005\n\n\n\n2006\n\n\n\n2007\n\n\n\n2008\n\n\n\n2009\n\n\n\n2010\n\n\n\n2011\n\n\n\n2012\n\n\n\n2013\n\n\n\n2014\n\n\n\n2015\n\n\n\n2016\n\n\n\n2017\n\n\n\n2018\n\n\n\n2019\n\n\n\n2020\n\n\n\n2021\n\n\n\n2022"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Age-adjusted COVID-19 mortality rates for Brazilian municipalities\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nERA5-Land selected indicators daily aggregates for Latin America\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nZonal statististics of climate indicators for Brazilian municipalities\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/query_remot_parquet_file.html",
    "href": "posts/query_remot_parquet_file.html",
    "title": "Query remote parquet files with DuckDB",
    "section": "",
    "text": "DuckDB has a very interesting extension called httpfs that allows to query CSV and parquet files remotely, including S3 storage.\nI will gave here an example about how to query a parquet file stored in a GitHub repository release."
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#remote-parquet-file",
    "href": "posts/query_remot_parquet_file.html#remote-parquet-file",
    "title": "Query remote parquet files with DuckDB",
    "section": "Remote parquet file",
    "text": "Remote parquet file\nFirst, I recommend to create an object with the URL of the parquet file. On the example bellow, the parquet file contains the nycflights13 flights database.\n\nparquet_url &lt;- \"https://github.com/rfsaldanha/releases/releases/download/v1/flights.parquet\"\n\nThis is a real URL. If you try to open it with your browser, a download will start."
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#duckdb-database-on-memory",
    "href": "posts/query_remot_parquet_file.html#duckdb-database-on-memory",
    "title": "Query remote parquet files with DuckDB",
    "section": "DuckDB database on memory",
    "text": "DuckDB database on memory\nNext, we create a DuckDB connection. Considering that the data is stored remotely, we can create this DuckDB database on memory and not on disk.\n\nconn &lt;- DBI::dbConnect(\n  duckdb::duckdb(),\n  dbdir = \":memory:\"\n)"
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#httpfs-extension",
    "href": "posts/query_remot_parquet_file.html#httpfs-extension",
    "title": "Query remote parquet files with DuckDB",
    "section": "httpfs extension",
    "text": "httpfs extension\nNow, we need to load the httpfs extension.\n\nDBI::dbExecute(conn, \"INSTALL httpfs;\")\n\n[1] 0\n\nDBI::dbExecute(conn, \"LOAD httpfs;\")\n\n[1] 0\n\n\n\n\n\n\n\n\nWindows users\n\n\n\nThe last time I checked, the httpfs extension was not working on Windows."
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#query",
    "href": "posts/query_remot_parquet_file.html#query",
    "title": "Query remote parquet files with DuckDB",
    "section": "Query",
    "text": "Query\nWe are ready to execute a query over the parquet file!\n\nres &lt;- DBI::dbGetQuery(\n  conn, \n  glue::glue(\"SELECT carrier, flight, tailnum, year FROM '{parquet_url}' WHERE year = 2013 LIMIT 100\")\n)\n\ndplyr::glimpse(res)\n\nRows: 100\nColumns: 4\n$ carrier &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"AA\", \"B…\n$ flight  &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 49, 71, …\n$ tailnum &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N39463\", \"N…\n$ year    &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 20…\n\n\nThis query selects some variables and filter the year, returning the first 100 rows. The query is carried out by DuckDB accessing the remote parquet file, but the file is not downloaded. That’s great!!\n\n\n\n\n\n\nTip\n\n\n\nQueries that needs more data and return more rows takes longer to run, especially transmitting data over the Internet. Craft carefully your queries with this in mind.\n\n\nIf you want to use dplyr verbs with the connection, you can create a view query.\n\nDBI::dbExecute(conn, glue::glue(\"CREATE VIEW flights AS SELECT * FROM PARQUET_SCAN('{parquet_url}')\"))\n\n[1] 0\n\n\n\nDBI::dbListTables(conn)\n\n[1] \"flights\"\n\n\n\nlibrary(dplyr)\n\ntbl(conn, \"flights\") %&gt;%\n  group_by(month) %&gt;%\n  summarise(freq = n()) %&gt;%\n  ungroup() %&gt;%\n  collect()\n\n# A tibble: 12 × 2\n   month  freq\n   &lt;int&gt; &lt;dbl&gt;\n 1     1 27004\n 2     2 24951\n 3     3 28834\n 4     4 28330\n 5     5 28796\n 6     6 28243\n 7     7 29425\n 8     8 29327\n 9     9 27574\n10    10 28889\n11    11 27268\n12    12 28135\n\n\nNow we can close the connection.\n\nDBI::dbDisconnect(conn, shutdown = TRUE)"
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#extra-duckdbfs-package",
    "href": "posts/query_remot_parquet_file.html#extra-duckdbfs-package",
    "title": "Query remote parquet files with DuckDB",
    "section": "Extra: duckdbfs package",
    "text": "Extra: duckdbfs package\nThe duckdbfs offers a neat way to connect to remote parquet files and other connections. The same example using the package:\n\nds &lt;- duckdbfs::open_dataset(parquet_url)\n\n\nds %&gt;%\n  group_by(month) %&gt;%\n  summarise(freq = n()) %&gt;%\n  ungroup() %&gt;%\n  collect()\n\n# A tibble: 12 × 2\n   month  freq\n   &lt;int&gt; &lt;dbl&gt;\n 1     1 27004\n 2     2 24951\n 3     3 28834\n 4     4 28330\n 5     5 28796\n 6     6 28243\n 7     7 29425\n 8     8 29327\n 9     9 27574\n10    10 28889\n11    11 27268\n12    12 28135"
  },
  {
    "objectID": "posts/query_remot_parquet_file.html#session-info",
    "href": "posts/query_remot_parquet_file.html#session-info",
    "title": "Query remote parquet files with DuckDB",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Paris\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.3\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.4       cli_3.6.1         knitr_1.45        rlang_1.1.2      \n [5] xfun_0.41         DBI_1.1.3         purrr_1.0.2       duckdbfs_0.0.3   \n [9] generics_0.1.3    jsonlite_1.8.7    glue_1.6.2        dbplyr_2.4.0     \n[13] htmltools_0.5.7   fansi_1.0.5       rmarkdown_2.25    evaluate_0.23    \n[17] tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7        lifecycle_1.0.3  \n[21] duckdb_0.9.1-1    compiler_4.3.2    blob_1.2.4        htmlwidgets_1.6.2\n[25] pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[29] tidyselect_1.2.0  utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3   \n[33] tools_4.3.2"
  },
  {
    "objectID": "posts/run_length_encoding.html",
    "href": "posts/run_length_encoding.html",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "",
    "text": "Some days ago I was trying to count how many times consecutive sequences with values higher than a reference appears in a data frame.\nFor example:\n\\(x = {2,2,3,4,4,5,6,7,3,7,7,1,6,7,8}\\)\nOn \\(x\\), how many times values higher than four appears in consecutive sequences with three or more elements?\nTwo times: the sequences \\(5,6,7\\) and \\(6,7,8\\).\nBut how to figure this out with R?"
  },
  {
    "objectID": "posts/run_length_encoding.html#run-length-encoding",
    "href": "posts/run_length_encoding.html#run-length-encoding",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "Run length encoding",
    "text": "Run length encoding\nBase R has an interesting function called Run Length Encoding: rle(x). Let’s see how this works with our example.\n\nx &lt;- c(2,2,3,4,4,5,6,7,3,7,7,1,6,7,8)\n\nrle(x)\n\nRun Length Encoding\n  lengths: int [1:12] 2 1 2 1 1 1 1 2 1 1 ...\n  values : num [1:12] 2 3 4 5 6 7 3 7 1 6 ...\n\n\nThe rle function returns a list of lengths and values. The “lengths” says how many times the “values” appears. The number two appears two times in sequence, then the number three appears one time, followed by a fours appearing two times, and so on…"
  },
  {
    "objectID": "posts/run_length_encoding.html#count-consecutive-sequences",
    "href": "posts/run_length_encoding.html#count-consecutive-sequences",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "Count consecutive sequences",
    "text": "Count consecutive sequences\nI created a little function (trle) to perform the following task: with a vector x, count consecutive sequences of length equal or higher than l that contains values equal or higher than v.\n\ntrle &lt;- function(x, l, v){\n1  x_logical &lt;- x &gt;= v\n  \n2  rle_list &lt;- rle(x_logical)\n\n3  rle_df &lt;- data.frame(\n    length = rle_list$lengths,\n    value = rle_list$values\n  )\n\n4  res_df &lt;- subset(rle_df, value == TRUE & length &gt;= l)\n  \n5  res &lt;- nrow(res_df)\n\n  return(res)\n}\n\n\n1\n\nCheck if each element of x is higher or equal to v. This will return a vector of true and false values.\n\n2\n\nRun the rle function over the sequence of true/false values.\n\n3\n\nConvert the list in a data frame object.\n\n4\n\nFilter rows where the value is equal to TRUE AND (&) have length higher than l.\n\n5\n\nCount the rows. That’s the result!\n\n\n\n\nLet’s test it with our example.\n\ntrle(x, l = 3, v = 4)\n\n[1] 2\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are probably better and faster ways to implement this. I focused on being simple and readable."
  },
  {
    "objectID": "posts/run_length_encoding.html#warm-spell-example",
    "href": "posts/run_length_encoding.html#warm-spell-example",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "Warm spell example",
    "text": "Warm spell example\nIn climatology there is an indicator called Warm Spell Duration Index (WSDI). A warm spell consist of at least six consecutive days with maximum temperatures higher than the climatological normal maximum temperature. A more formal definition can be found here.\nWe can get some temperature values with the brclimr package for Rio de Janeiro, Brazil.\n\nrio &lt;- brclimr::fetch_data(\n  code_muni = 3304557,\n  product = \"brdwgd\", \n  indicator = \"tmax\", \n  statistics = \"mean\", \n  date_start = as.Date(\"2020-01-01\"),\n  date_end = as.Date(\"2020-12-31\")\n)\n\nhead(rio, 10)\n\n# A tibble: 10 × 2\n   date       value\n   &lt;date&gt;     &lt;dbl&gt;\n 1 2020-01-01  36.0\n 2 2020-01-02  31.1\n 3 2020-01-03  27.9\n 4 2020-01-04  28.5\n 5 2020-01-05  28.4\n 6 2020-01-06  34.1\n 7 2020-01-07  35.8\n 8 2020-01-08  32.8\n 9 2020-01-09  33.4\n10 2020-01-10  33.7\n\n\nLet’s assume the reference value as 30 Celsius degrees. How many sequences of six days or more had temperatures equal or higher than 30?\n\ntrle(x = rio$value, l = 6, v = 30)\n\n[1] 3\n\n\nThis happened three times on 2020. Try to find them at the graph bellow:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data = rio, aes(x = date, y = value)) +\n  geom_line(color = \"purple\", alpha = .7) +\n  geom_point(color = \"purple\", alpha = .7) +\n  geom_hline(yintercept = 30, color = \"red\", alpha = .7) +\n  theme_classic()"
  },
  {
    "objectID": "posts/run_length_encoding.html#length-and-positions-of-consecutive-events",
    "href": "posts/run_length_encoding.html#length-and-positions-of-consecutive-events",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "Length and positions of consecutive events",
    "text": "Length and positions of consecutive events\nWould be nice if the function returned also when those sequences happened, right? We can change our little function a little bit to return the dates and actual lengths of those sequences, adding an index vector i as argument.\n\ntrle2 &lt;- function(x, i, l, v){\n1  x_logical &lt;- x &gt;= v\n  \n2  rle_list &lt;- rle(x_logical)\n\n3  rle_df &lt;- data.frame(\n    length = rle_list$lengths,\n    value = rle_list$values\n  )\n\n4  rle_df$pos_2 &lt;- cumsum(rle_df$length)\n  rle_df$pos_1 &lt;- rle_df$pos_2 - rle_df$length + 1\n\n5  rle_df &lt;- data.frame(\n    pos_1 = i[rle_df$pos_1],\n    pos_2 = i[rle_df$pos_2],\n    length = rle_df$length,\n    value = rle_df$value\n  )\n\n6  res &lt;- subset(rle_df, value == TRUE & length &gt;= l)\n7  res$value &lt;- NULL\n8  rownames(res) &lt;- NULL\n\n9  return(res)\n}\n\n\n1\n\nCheck if each element of x is higher or equal to v. This will return a vector of true and false values.\n\n2\n\nRun the rle function over the sequence of true/false values.\n\n3\n\nConvert the list in a data frame object.\n\n4\n\nEstablish the start (pos_1) and end (pos_2) positions of each sequence. The end position is the cumulative sum of the lengths. The start position is equivalent to the end position minus the length plus one.\n\n5\n\nCreate a data frame with the equivalent positions on the vector i and the length and values of the sequences\n\n6\n\nFilter rows where the value is equal to TRUE AND (&) have length higher than l.\n\n7\n\nRemove the value variable.\n\n8\n\nRemove row names.\n\n9\n\nReturn the data frame as result.\n\n\n\n\n\nres &lt;- trle2(x = rio$value, i = rio$date, l = 6, v = 30)\n\nres\n\n       pos_1      pos_2 length\n1 2020-01-06 2020-01-12      7\n2 2020-01-26 2020-02-03      9\n3 2020-02-15 2020-02-21      7\n\n\nTo see that on the graph, we can use some lubridate functions. First, we create a list of date intervals.\n\nlibrary(lubridate)\n\nintervals &lt;- as.list(lubridate::interval(res$pos_1, res$pos_2))\n\nThen, we check if the dates are within those intervals.\n\nrio$test &lt;- rio$date %within% intervals\n\nhead(rio, 10)\n\n# A tibble: 10 × 3\n   date       value test \n   &lt;date&gt;     &lt;dbl&gt; &lt;lgl&gt;\n 1 2020-01-01  36.0 FALSE\n 2 2020-01-02  31.1 FALSE\n 3 2020-01-03  27.9 FALSE\n 4 2020-01-04  28.5 FALSE\n 5 2020-01-05  28.4 FALSE\n 6 2020-01-06  34.1 TRUE \n 7 2020-01-07  35.8 TRUE \n 8 2020-01-08  32.8 TRUE \n 9 2020-01-09  33.4 TRUE \n10 2020-01-10  33.7 TRUE \n\n\nAnd plot it!\n\nggplot(data = rio, aes(x = date, y = value)) +\n  geom_line(color = \"purple\", alpha = .7) +\n  geom_point(aes(color = test), alpha = .7) +\n  geom_hline(yintercept = 30, color = \"red\", alpha = .7) +\n  scale_color_manual(values=c(\"#999999\", \"#E69F00\")) +\n  theme_classic() +\n  theme(legend.position = \"bottom\", legend.direction = \"horizontal\")"
  },
  {
    "objectID": "posts/run_length_encoding.html#session-info",
    "href": "posts/run_length_encoding.html#session-info",
    "title": "Counting consecutive sequences of events: run length encoding and warm spell occurence example",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Paris\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lubridate_1.9.3 scales_1.2.1    ggplot2_3.4.4  \n\nloaded via a namespace (and not attached):\n [1] bit_4.0.5         gtable_0.3.4      jsonlite_1.8.7    dplyr_1.1.3      \n [5] compiler_4.3.2    tidyselect_1.2.0  assertthat_0.2.1  arrow_13.0.0.1   \n [9] yaml_2.3.7        fastmap_1.1.1     R6_2.5.1          labeling_0.4.3   \n[13] generics_0.1.3    brclimr_0.1.2     knitr_1.45        htmlwidgets_1.6.2\n[17] backports_1.4.1   checkmate_2.3.0   tibble_3.2.1      munsell_0.5.0    \n[21] pillar_1.9.0      rlang_1.1.2       utf8_1.2.4        xfun_0.41        \n[25] bit64_4.0.5       timechange_0.2.0  cli_3.6.1         withr_2.5.2      \n[29] magrittr_2.0.3    digest_0.6.33     grid_4.3.2        rstudioapi_0.15.0\n[33] lifecycle_1.0.3   vctrs_0.6.4       evaluate_0.23     glue_1.6.2       \n[37] farver_2.1.1      colorspace_2.1-0  fansi_1.0.5       rmarkdown_2.25   \n[41] purrr_1.0.2       tools_4.3.2       pkgconfig_2.0.3   htmltools_0.5.7"
  },
  {
    "objectID": "posts/sqlite_to_duckdb_and_parquet.html",
    "href": "posts/sqlite_to_duckdb_and_parquet.html",
    "title": "SQLite database conversion to DuckDB and Parquet files",
    "section": "",
    "text": "DuckDB is a relatively new database that works in a file, just like SQLite, but is very fast and designed for data science workflows.\nI am writing this post to cover the following scenario: you already have a SQLite database and want to convert it to DuckDB, and also export it to a parquet file."
  },
  {
    "objectID": "posts/sqlite_to_duckdb_and_parquet.html#sqlite-database",
    "href": "posts/sqlite_to_duckdb_and_parquet.html#sqlite-database",
    "title": "SQLite database conversion to DuckDB and Parquet files",
    "section": "SQLite database",
    "text": "SQLite database\nWe need a SQLite database example to later convert it to DuckDB. Let’s use the mtcars dataset.\n\nlibrary(dplyr)\nlibrary(lubridate)\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\nAnd write mtcars in a SQLite database.\n\nsqlite_database_file &lt;- tempfile()\n\nconn_sqlite &lt;- DBI::dbConnect(\n  RSQLite::SQLite(), \n  sqlite_database_file, \n  extended_types = TRUE\n)\n\nDBI::dbWriteTable(conn_sqlite, name = \"mtcars_table\", value = mtcars, overwrite = TRUE)\n\nLet’s take a look.\n\ntbl(conn_sqlite, \"mtcars_table\") %&gt;% head() %&gt;% collect()\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this database could be written directly using DuckDB, but this is an example about database conversion."
  },
  {
    "objectID": "posts/sqlite_to_duckdb_and_parquet.html#from-sqlite-to-duckdb",
    "href": "posts/sqlite_to_duckdb_and_parquet.html#from-sqlite-to-duckdb",
    "title": "SQLite database conversion to DuckDB and Parquet files",
    "section": "From SQLite to DuckDB",
    "text": "From SQLite to DuckDB\nFirst, we need to create our DuckDB database.\n\nduckdb_database_file &lt;- tempfile()\n\nconn_duckdb &lt;- DBI::dbConnect(\n  duckdb::duckdb(), \n  duckdb_database_file\n)\n\nTo import our data, we can use a DuckDB extension to read SQLite databases.\n\nDBI::dbExecute(conn_duckdb, \"INSTALL sqlite;\")\n\n[1] 0\n\nDBI::dbExecute(conn_duckdb, \"LOAD sqlite;\")\n\n[1] 0\n\n\n\nDBI::dbExecute(conn_duckdb, glue::glue(\"CREATE TABLE mtcars_table AS SELECT * FROM sqlite_scan('{sqlite_database_file}', 'mtcars_table');\"))\n\n[1] 32\n\n\nGreat! Now we have the same database on DuckDB."
  },
  {
    "objectID": "posts/sqlite_to_duckdb_and_parquet.html#from-duckdb-to-parquet",
    "href": "posts/sqlite_to_duckdb_and_parquet.html#from-duckdb-to-parquet",
    "title": "SQLite database conversion to DuckDB and Parquet files",
    "section": "From DuckDB to Parquet",
    "text": "From DuckDB to Parquet\nIt is very simple to export a DuckDB table to a parquet file.\n\nparquet_file &lt;- tempfile()\n\nDBI::dbExecute(conn_duckdb, glue::glue(\"COPY (SELECT * FROM 'mtcars_table') TO '{parquet_file}' (FORMAT 'PARQUET')\"))\n\n[1] 32\n\n\nAnd that’s it! Let’s close the connections.\n\nDBI::dbDisconnect(conn_sqlite)\nDBI::dbDisconnect(conn_duckdb, shutdown = TRUE)"
  },
  {
    "objectID": "posts/sqlite_to_duckdb_and_parquet.html#session-info",
    "href": "posts/sqlite_to_duckdb_and_parquet.html#session-info",
    "title": "SQLite database conversion to DuckDB and Parquet files",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Paris\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lubridate_1.9.3 dplyr_1.1.3    \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.4       cli_3.6.1         knitr_1.44        rlang_1.1.1      \n [5] xfun_0.40         DBI_1.1.3         purrr_1.0.2       generics_0.1.3   \n [9] jsonlite_1.8.7    bit_4.0.5         glue_1.6.2        dbplyr_2.3.4     \n[13] htmltools_0.5.6.1 hms_1.1.3         fansi_1.0.5       rmarkdown_2.25   \n[17] evaluate_0.22     tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7       \n[21] lifecycle_1.0.3   memoise_2.0.1     duckdb_0.9.1      compiler_4.3.1   \n[25] blob_1.2.4        RSQLite_2.3.1     htmlwidgets_1.6.2 timechange_0.2.0 \n[29] pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[33] tidyselect_1.2.0  utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3   \n[37] bit64_4.0.5       tools_4.3.1       cachem_1.0.8"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Harmonize\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nMonitoraCovid-19\n\n\nCovid-19 monitoring.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOuvSUS\n\n\nSUS Ombudsman.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPNS\n\n\nPesquisa Nacional de Saúde.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCross-border malaria\n\n\nIn partnership with IRD.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nRedes de Cuidado\n\n\nCancer patients displacement and network analysis.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nArboAlvo\n\n\nStratifying arboviruses risk.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOnde estão nossas doenças?\n\n\nMuseum exhibition.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPMM\n\n\nProjeto Mais Médicos.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nÁgua & Saúde\n\n\nIn partneship with ANA.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nMauro\n\n\na Metadata Automatic Retrieval system for Updated References and cited Objects from Scielo.\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCidade & Saúde\n\n\nAccessible health information about Brazilian municipalities.\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "projects/arboalvo.html",
    "href": "projects/arboalvo.html",
    "title": "ArboAlvo",
    "section": "",
    "text": "ArboAlvo dashboard.\n\n\nConducted at the Instituto Oswaldo Cruz (IOC), the project ArboAlvo’s objective is to stratify arboviruses risk into national and intra-municipal levels, considering epidemiolocal, entomological, and socio-demographic dimensions.\nI participated in this project by creating, reviewing, and optimizing code in the project data analysis, and developing data dashboards.\n\n\n\nArboAlvo dashboard running on Natal local server.\n\n\n\n\n\nWith the Natal IT team, August 8, 2022.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/cross-border-malaria.html",
    "href": "projects/cross-border-malaria.html",
    "title": "Cross-border malaria",
    "section": "",
    "text": "Cross-border malaria main webpage.\n\n\nThis was the second project that I got involved at Fiocruz with the Climate and Health Observatory. It was a project in partnership with the French IRD (Institute de Recherche pour le Développement).\nI was in charge to provide knowledge about the malaria databases in Brazil (SIVEP-Malária) and developing a data dashboard showing cross-border malaria transmission on the French Guiana and Brazil (Amapá) frontier. This was an especially difficult task considering that the dashboard needed to be present in English, French, and Portuguese. The dashboard was developed with R and Shiny technology.\nThis project involved a whole month trip to Montpellier, France to engage with other team members and also a trip to Cayenne, the French Guiana capital to learn firsthand how data was collected and handled.\nThis project resulted in two published papers: http://dx.doi.org/10.1186/s12879-020-05086-4 and http://dx.doi.org/10.2196/15409.\nThis work was supported by a grant from Bill & Mellinda Gates Foundation.\n\n\n\nIRD\n\n\n\n\n\nMaison de la Télédétection\n\n\n\n\n\nProject first sketches on board (Montpellier, France).\n\n\n\n\n\nProject presentation at Cayenne by Dr. Emmanuel Roux, coordinator.\n\n\n\n\n\nSome leisure time at Cayenne.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/mauro.html",
    "href": "projects/mauro.html",
    "title": "Mauro",
    "section": "",
    "text": "Mauro main webpage.\n\n\n“Mauro” was a research project that I initiated during my Ph.D. at Fiocruz, when I was taking some courses about technological information on health.\nThe objectives of the project were (1) to download and organize bibliometric information available at “Scielo” from the Public Health, and Brazil collections. (2) Provide a simple and intuitive way for researchers to access its data through filters and visualize information.\nThe ETL process and dashboard were developed with R and Shiny. The project is now deactivated.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/onde-estao-nossas-doencas.html",
    "href": "projects/onde-estao-nossas-doencas.html",
    "title": "Onde estão nossas doenças?",
    "section": "",
    "text": "Exhibition visitors using the interactive map.\n\n\nThis was a very special project, where we were invited to develop a museum exhibition at Fiocruz. On this set, we present to the visitors the relationship between health and space by using interactive maps in a wide display and also with printed and tactile special maps for visually impaired visitors.\nThe exhibition is permanent and located at the Fiocruz Maré Campus.\nThe interactive map can also be accessed here: https://rfsaldanha.github.io/app_cavalarica/\n\n\n\nTactile map for visually impaired visitors.\n\n\n\n\n\nFiocruz president, Dra. Nisia Trindade, contemplating the exhibition.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/pmm.html",
    "href": "projects/pmm.html",
    "title": "PMM",
    "section": "",
    "text": "PMM main webpage.\n\n\n“Projeto Mais Médicos” was the first project that I got involved with at Fiocruz, through the PCDaS initiative. I was in charge of developing a data dashboard and to coordinate a team with other research assistants.\nThe project aimed to present data about a federal project called “Mais Médicos”, where a public health policy encouraged MDs to work in less developed regions in Brazil and also contracted foreign MDs from Cuba and other countries to work on those regions.\nThe project has been discontinued.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/redes-de-cuidado.html",
    "href": "projects/redes-de-cuidado.html",
    "title": "Redes de Cuidado",
    "section": "",
    "text": "Commuting networks of patients that received cancer treatment within SUS, from article http://dx.doi.org/10.1016/j.lana.2021.100153.\n\n\nThis project was a partnership with PCDaS and CDTS. The project studied the flow of cancer patients receiving treatment in Brazil between municipalities.\nI was in charge to handle the large datasets about hospitalizations and treatments and perform some network analysis.\nThis work was supported by Inova Fiocruz and resulted in a published paper: http://dx.doi.org/10.1016/j.lana.2021.100153.\n\n\n\n Back to top"
  },
  {
    "objectID": "publications/araujoWHATHAVEWE2019a.html",
    "href": "publications/araujoWHATHAVEWE2019a.html",
    "title": "What have we learned from Mariana? The importance of names, places and affections",
    "section": "",
    "text": "ARAÚJO, N. et al. WHAT HAVE WE LEARNED FROM MARIANA? THE IMPORTANCE OF NAMES, PLACES AND AFFECTIONS. Ambiente & Sociedade, v. 22, p. e00002, May 2019.\n\n\nNaming is an ambitious task. Naming an object or event means recognizing, distinguishing and giving importance to it. Whoever names acquires power over what was previously indescribable. The name is sign and meaning, skewed in origin and use. Naming and understanding the complexity of what occurred in the city of Mariana and its causes and consequences represents a challenge for which disciplinary approaches centered on scientific knowledge are insufficient. Thus, our search for studies on what happened in Mariana after the failure of the Fundão Dam in November 2015 should be complemented by the stories of residents of that place, by their knowledge. We recognize that this approach to examining such an issue would only be a limited contribution and thus constitutes the primary condition for an interdisciplinary exercise."
  },
  {
    "objectID": "publications/araujoWHATHAVEWE2019a.html#reference",
    "href": "publications/araujoWHATHAVEWE2019a.html#reference",
    "title": "What have we learned from Mariana? The importance of names, places and affections",
    "section": "",
    "text": "ARAÚJO, N. et al. WHAT HAVE WE LEARNED FROM MARIANA? THE IMPORTANCE OF NAMES, PLACES AND AFFECTIONS. Ambiente & Sociedade, v. 22, p. e00002, May 2019.\n\n\nNaming is an ambitious task. Naming an object or event means recognizing, distinguishing and giving importance to it. Whoever names acquires power over what was previously indescribable. The name is sign and meaning, skewed in origin and use. Naming and understanding the complexity of what occurred in the city of Mariana and its causes and consequences represents a challenge for which disciplinary approaches centered on scientific knowledge are insufficient. Thus, our search for studies on what happened in Mariana after the failure of the Fundão Dam in November 2015 should be complemented by the stories of residents of that place, by their knowledge. We recognize that this approach to examining such an issue would only be a limited contribution and thus constitutes the primary condition for an interdisciplinary exercise."
  },
  {
    "objectID": "publications/camposFatoresAssociadosAo2020b.html#reference",
    "href": "publications/camposFatoresAssociadosAo2020b.html#reference",
    "title": "Fatores associados ao letramento funcional em saúde de mulheres atendidas pela Estratégia de Saúde da Família",
    "section": "Reference",
    "text": "Reference\n\n\nCAMPOS, A. A. L. et al. Fatores associados ao letramento funcional em saúde de mulheres atendidas pela Estratégia de Saúde da Família. Cadernos Saúde Coletiva, v. 28, p. 66–76, Apr. 2020."
  },
  {
    "objectID": "publications/camposFatoresAssociadosAo2020b.html#abstract",
    "href": "publications/camposFatoresAssociadosAo2020b.html#abstract",
    "title": "Fatores associados ao letramento funcional em saúde de mulheres atendidas pela Estratégia de Saúde da Família",
    "section": "Abstract",
    "text": "Abstract\nIntrodução. O letramento funcional em saúde (LFS) diz respeito à habilidade dos indivíduos em compreender as informações relacionadas à saúde e está relacionado a diversos desfechos de saúde. Objetivo. Investigar a associação do LFS com fatores sociodemográficos, apoio social, autoavaliação do estado de saúde e perfil de acesso aos serviços de saúde em mulheres assistidas pela Estratégia de Saúde da Família (ESF). Método. Estudo transversal, conduzido em 2015-2016, em duas Unidades de Atenção Primária à Saúde cobertas pela ESF, de um município da região Sudeste do Brasil. A amostra foi composta por 439 mulheres, entre 25 e 64 anos. O LFS foi avaliado por meio do Brief Test of Functional Health Literacy in Adults (B-TOFHLA). Efetuaram-se cálculos da razão de prevalência (RP). Posteriormente, construiu-se um modelo de regressão de Poisson de variância robusta, sendo admitida significância estatística quando p ≤0,05. Resultados. Foi constatado que 53,5% das mulheres apresentaram um baixo LFS, o qual associou-se à idade superior aos 40 anos (RP = 1,18; IC 95%: 1,07-1,31), ao grau de instrução inferior ao ensino médio completo (RP = 1,26; IC 95%: 1,15-1,38), à baixa renda (RP = 1,13; IC 95%: 1,04-1,23) e à autodeclaração da cor parda ou preta (RP= 1,06; IC 95%: 1,01-1,12). Conclusão. Os resultados acentuaram a importância do LFS como estratégia para a abordagem de populações com maior vulnerabilidade socioeconômica."
  },
  {
    "objectID": "publications/goncalvesCrescimentoEmpregoIndustrial2019a.html#reference",
    "href": "publications/goncalvesCrescimentoEmpregoIndustrial2019a.html#reference",
    "title": "Crescimento do emprego industrial local no Brasil: o grau de especialização por intensidade tecnológica importa?",
    "section": "Reference",
    "text": "Reference\n\n\nGONÇALVES, E. et al. Crescimento do emprego industrial local no Brasil: o grau de especialização por intensidade tecnológica importa? Nova Economia, v. 29, p. 41–74, May 2019."
  },
  {
    "objectID": "publications/goncalvesCrescimentoEmpregoIndustrial2019a.html#abstract",
    "href": "publications/goncalvesCrescimentoEmpregoIndustrial2019a.html#abstract",
    "title": "Crescimento do emprego industrial local no Brasil: o grau de especialização por intensidade tecnológica importa?",
    "section": "Abstract",
    "text": "Abstract\nThe aim of this paper is to revisit the debate on the degree of specialization and industrial diversification and the growth of local manufacturing employment in Brazil. A matrix of sectoral spillovers is built in which it is verified whether sectors, grouped by technological intensity, influence the performance of disaggregated manufacturing groups. Spatial data panel techniques are used to control non-observed local effects and possible spatial dependence over the period 1995-2014. The results show that specializations in low-technology manufacturing groups create stimulus for several other manufacturing groups regardless of the level of technological intensity. The spillovers coming from high technology manufacturing industries are less frequent, though they also occur depending on the industrial manufacturing group considered. In general, sectors of higher and lower technological intensity flourish with the presence of MAR externalities. We conclude that the diversification/specialization debate can vary considerably, requiring specific industrial and regional policies by manufacturing industries."
  },
  {
    "objectID": "publications/guimaraesIncreasingImpactCOVID192021b.html#reference",
    "href": "publications/guimaraesIncreasingImpactCOVID192021b.html#reference",
    "title": "Increasing impact of COVID-19 on young adults: evidence from hospitalisations in Brazil",
    "section": "Reference",
    "text": "Reference\n\n\nGUIMARÃES, R. et al. Increasing impact of COVID-19 on young adults: Evidence from hospitalisations in Brazil. Public Health, v. 198, p. 297–300, Sep. 2021."
  },
  {
    "objectID": "publications/guimaraesIncreasingImpactCOVID192021b.html#abstract",
    "href": "publications/guimaraesIncreasingImpactCOVID192021b.html#abstract",
    "title": "Increasing impact of COVID-19 on young adults: evidence from hospitalisations in Brazil",
    "section": "Abstract",
    "text": "Abstract\n\nObjectives\nConcerns about the increasing impact of severe COVID-19 in younger individuals in Brazil came after a recent synchronised country-wide wave of cases in Brazil. This communication analyses how hospitalisations due to COVID-19 changed in the age groups 18–49 years and ≥70 years.\n###Study design Longitudinal study based on secondary data.\n\n\nMethods\nData from SIVEP-Gripe, a public and open-access database of Severe Acute Respiratory Illness records (including COVID-19 notifications), were used in this study. Statistical control charts examined changes in the magnitude and variation of younger (18–49 years) and older (≥70 years) adults who were hospitalised between 15th March 2020 and 19th June 2021.\n\n\nResults\nDuring the few first weeks of the pandemic in Brazil, the number of COVID-19 hospitalisations increased in older adults but decreased in younger adults. Subsequently, hospitalisations reached statistical control zones in epidemiological weeks (EW) 19–48 of 2020 (EW 19-48/2020) and EW 03-05/2021 (18–49 y, mean = 26.1%; ≥70 y, mean = 32.8%). Between EW 49/2020 and EW 02/2021, the number of hospitalisations of younger adults dropped to levels below the lower control limit. In contrast, the number of hospitalisations of older adults surpassed the upper limit of the corresponding statistical control zones. However, from EW 06/2021, numbers of hospitalisations changed from statistical control zones, with hospitalisations of younger adults increasing and reaching 44.9% in EW 24/2021 and hospitalisations of older adults decreasing until EW 19/2021 (14.1%) and reaching 17.3% in EW 24/2021.\n\n\nConclusions\nAn increasing number of COVID-19 hospitalisations were observed in younger adults from EW 06/2021. This could be a result of the successful vaccination programme in older adults, who were initially prioritised, and possibly an increased exposure to highly transmissible variants of COVID-19 in younger adults who had to go to work in the absence of social protection (i.e. government financial support). Potential consequences of COVID-19 hospitalisations in younger adults could include a reduced life expectancy of the population and an increased number of people unable to perform daily activities due to post-COVID-19 conditions."
  },
  {
    "objectID": "publications/marinhoBurdenDiseaseBrazil2018.html#reference",
    "href": "publications/marinhoBurdenDiseaseBrazil2018.html#reference",
    "title": "Burden of disease in Brazil, 1990–2016: a systematic subnational analysis for the Global Burden of Disease Study 2016",
    "section": "Reference",
    "text": "Reference\n\n\nMARINHO, F. et al. Burden of disease in Brazil, 1990: A systematic subnational analysis for the Global Burden of Disease Study 2016. The Lancet, v. 392, n. 10149, p. 760–775, Sep. 2018."
  },
  {
    "objectID": "publications/marinhoBurdenDiseaseBrazil2018.html#abstract",
    "href": "publications/marinhoBurdenDiseaseBrazil2018.html#abstract",
    "title": "Burden of disease in Brazil, 1990–2016: a systematic subnational analysis for the Global Burden of Disease Study 2016",
    "section": "Abstract",
    "text": "Abstract\n\nBackground\nPolitical, economic, and epidemiological changes in Brazil have affected health and the health system. We used the Global Burden of Disease Study 2016 (GBD 2016) results to understand changing health patterns and inform policy responses.\n\n\nMethods\nWe analysed GBD 2016 estimates for life expectancy at birth (LE), healthy life expectancy (HALE), all-cause and cause-specific mortality, years of life lost (YLLs), years lived with disability (YLDs), disability-adjusted life-years (DALYs), and risk factors for Brazil, its 26 states, and the Federal District from 1990 to 2016, and compared these with national estimates for ten comparator countries.\n\n\nFindings\nNationally, LE increased from 68·4 years (95% uncertainty interval [UI] 68·0–68·9) in 1990 to 75·2 years (74·7–75·7) in 2016, and HALE increased from 59·8 years (57·1–62·1) to 65·5 years (62·5–68·0). All-cause agestandardised mortality rates decreased by 34·0% (33·4–34·5), while all-cause age-standardised DALY rates decreased by 30·2% (27·7–32·8); the magnitude of declines varied among states. In 2016, ischaemic heart disease was the leading cause of age-standardised YLLs, followed by interpersonal violence. Low back and neck pain, sense organ diseases, and skin diseases were the main causes of YLDs in 1990 and 2016. Leading risk factors contributing to DALYs in 2016 were alcohol and drug use, high blood pressure, and high body-mass index.\n\n\nInterpretation\nHealth improved from 1990 to 2016, but improvements and disease burden varied between states. An epidemiological transition towards non-communicable diseases and related risks occurred nationally, but later in some states, while interpersonal violence grew as a health concern. Policy makers can use these results to address health disparities.\n\n\nFunding\nBill & Melinda Gates Foundation and the Brazilian Ministry of Health."
  },
  {
    "objectID": "publications/paixaoEstimationCOVID19UnderReporting2021a.html#reference",
    "href": "publications/paixaoEstimationCOVID19UnderReporting2021a.html#reference",
    "title": "Estimation of COVID-19 Under-Reporting in the Brazilian States Through SARI",
    "section": "Reference",
    "text": "Reference\n\n\nPAIXÃO, B. et al. Estimation of COVID-19 Under-Reporting in the Brazilian States Through SARI. New Generation Computing, v. 39, n. 3, p. 623–645, Nov. 2021."
  },
  {
    "objectID": "publications/paixaoEstimationCOVID19UnderReporting2021a.html#abstract",
    "href": "publications/paixaoEstimationCOVID19UnderReporting2021a.html#abstract",
    "title": "Estimation of COVID-19 Under-Reporting in the Brazilian States Through SARI",
    "section": "Abstract",
    "text": "Abstract\nDue to its impact, COVID-19 has been stressing the academy to search for curing, mitigating, or controlling it. It is believed that under-reporting is a relevant factor in determining the actual mortality rate and, if not considered, can cause significant misinformation. Therefore, this work aims to estimate the under-reporting of cases and deaths of COVID-19 in Brazilian states using data from the InfoGripe. InfoGripe targets notifications of Severe Acute Respiratory Infection (SARI). The methodology is based on the combination of data analytics (event detection methods) and time series modeling (inertia and novelty concepts) over hospitalized SARI cases. The estimate of real cases of the disease, called novelty, is calculated by comparing the difference in SARI cases in 2020 (after COVID-19) with the total expected cases in recent years (2016–2019). The expected cases are derived from a seasonal exponential moving average. The results show that under-reporting rates vary significantly between states and that there are no general patterns for states in the same region in Brazil. The states of Minas Gerais and Mato Grosso have the highest rates of under-reporting of cases. The rate of under-reporting of deaths is high in the Rio Grande do Sul and the Minas Gerais. This work can be highlighted for the combination of data analytics and time series modeling. Our calculation of under-reporting rates based on SARI is conservative and better characterized by deaths than for cases."
  },
  {
    "objectID": "publications/saldanhaContributingEliminationCrossBorder2020.html#reference",
    "href": "publications/saldanhaContributingEliminationCrossBorder2020.html#reference",
    "title": "Contributing to Elimination of Cross-Border Malaria Through a Standardized Solution for Case Surveillance, Data Sharing, and Data Interpretation: Development of a Cross-Border Monitoring System",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "publications/saldanhaContributingEliminationCrossBorder2020.html#abstract",
    "href": "publications/saldanhaContributingEliminationCrossBorder2020.html#abstract",
    "title": "Contributing to Elimination of Cross-Border Malaria Through a Standardized Solution for Case Surveillance, Data Sharing, and Data Interpretation: Development of a Cross-Border Monitoring System",
    "section": "Abstract",
    "text": "Abstract\n\nBackground\nCross-border malaria is a significant obstacle to achieving malaria control and elimination worldwide. Objective: This study aimed to build a cross-border surveillance system that can make comparable and qualified data available to all parties involved in malaria control between French Guiana and Brazil.\n\n\nMethods\nData reconciliation rules based on expert knowledge were defined and applied to the heterogeneous data provided by the existing malaria surveillance systems of both countries. Visualization dashboards were designed to facilitate progressive data exploration, analysis, and interpretation. Dedicated advanced open source and robust software solutions were chosen to facilitate solution sharing and reuse.\n\n\nResults\nA database gathering the harmonized data on cross-border malaria epidemiology is updated monthly with new individual malaria cases from both countries. Online dashboards permit a progressi ve and user-friendly visualization of raw data and epidemiological indicators, in the form of time series, maps, and data quality indexes. The monitoring system was shown to be able to identify changes in time series that are related to control actions, as well as differentiated changes according to space and to population subgroups.\n\n\nConclusions\nThis cross-border monitoring tool could help produce new scientific evidence on cross-border malaria dynamics, implementing cross-border cooperation for malaria control and elimination, and can be quickly adapted to other cross-border contexts."
  },
  {
    "objectID": "publications/saldanhaMicrodatasusPacotePara2019.html#reference",
    "href": "publications/saldanhaMicrodatasusPacotePara2019.html#reference",
    "title": "Microdatasus: pacote para download e pré-processamento de microdados do Departamento de Informática do SUS (DATASUS)",
    "section": "Reference",
    "text": "Reference\n\n\nSALDANHA, R. DE F.; BASTOS, R. R.; BARCELLOS, C. Microdatasus: pacote para download e pré-processamento de microdados do Departamento de Informática do SUS (DATASUS). Cadernos de Saúde Pública, v. 35, p. e00032419, Sep. 2019."
  },
  {
    "objectID": "publications/saldanhaMicrodatasusPacotePara2019.html#abstract",
    "href": "publications/saldanhaMicrodatasusPacotePara2019.html#abstract",
    "title": "Microdatasus: pacote para download e pré-processamento de microdados do Departamento de Informática do SUS (DATASUS)",
    "section": "Abstract",
    "text": "Abstract\nThis study aimed to develop an algorithm for downloading and preprocessing microdata furnished by the Brazilian Health Informatics Department (DATASUS) for various health information systems, using the R statistical programming language. The package allows downloading and preprocessing data from various health information systems, with the inclusion of labeling categorical fields in the files. The download function was capable of directly accessing and reducing the workload for the selection of microdata files and variables in DATASUS, while the preprocessing function enabled automatic coding of various categorical fields. The package thus enables a continuous workflow in the same program, in which the algorithm allows downloading and preprocessing and other packages in R allow analyzing data from the health information systems in the Brazilian Unified National Health System (SUS)."
  },
  {
    "objectID": "publications/saldanhaPropostaUmObservatorio2017.html#reference",
    "href": "publications/saldanhaPropostaUmObservatorio2017.html#reference",
    "title": "Proposta de um observatório epidemiológico do Sistema Único de Saúde",
    "section": "Reference",
    "text": "Reference\n\n\nSALDANHA, R. DE F. et al. Proposta de um observatório epidemiológico do Sistema Único de Saúde. Cadernos de Saúde Pública, v. 33, p. e00113216, Jan. 2017."
  },
  {
    "objectID": "publications/saldanhaPropostaUmObservatorio2017.html#abstract",
    "href": "publications/saldanhaPropostaUmObservatorio2017.html#abstract",
    "title": "Proposta de um observatório epidemiológico do Sistema Único de Saúde",
    "section": "Abstract",
    "text": "Abstract\nFollowing the creation of the Brazilian Unified National Health System (SUS), the Brazilian Health Informatics Department (DATASUS) was established in 1991, aimed at organizing information systems and databases in health. Online data access and viewing is free and open, using tables and graphs of aggregate data and access to raw data. However, the current form of data access does not fully meet the demands by health system administrators and other users for a flexible, user-friendly tool that allows dealing with various relevant health issues in the knowledge search and decision-making. We propose an ancillary system capable of generating monthly summary reports that are easy to access and understand, with an emphasis on viewing information through graphs and maps."
  },
  {
    "objectID": "publications/silvaTemporalSpatialDistribution2022.html#reference",
    "href": "publications/silvaTemporalSpatialDistribution2022.html#reference",
    "title": "Temporal and spatial distribution trends of polio vaccine coverage in children in Brazil, 2011-2021",
    "section": "Reference",
    "text": "Reference\n\n\nSILVA, T. M. R. D. et al. Temporal and spatial distribution trends of polio vaccine coverage in children in Brazil, 2011-2021. [s.l.] In Review, Aug. 2022. Acesso em: 30 sep. 2023."
  },
  {
    "objectID": "publications/silvaTemporalSpatialDistribution2022.html#abstract",
    "href": "publications/silvaTemporalSpatialDistribution2022.html#abstract",
    "title": "Temporal and spatial distribution trends of polio vaccine coverage in children in Brazil, 2011-2021",
    "section": "Abstract",
    "text": "Abstract\nBackground: Low polio vaccine coverage can result in the spread of Poliovirus to areas free from viral circulation. This study analyzed the temporal trends and spatial distribution of polio vaccine coverage for children under five years of age in Brazil, between 2011 and 2021. Methods: This is an ecological, time-series study (2011 to 2021) with annual vaccine coverages against poliomyelitis, extracted from the Information System of the National Immunization Program from regions of the 27 Brazilian states. The percentage reductions in vaccination coverage in Brazil and in the Regions were calculated. Prais-Winsten regression models were used to analyze time series for the Regions and States, and spatial analysis identified the distribution of clusters (high-high; low-low; high-low and lowhigh) of vaccination coverages across Brazilian municipalities, using a 5% significance level. Results: From 2011 to 2021, the coverage of polio vaccines decreased by 46.1%. There was a progressive increase observed in clusters resulting in low vaccination coverages (136 low-low Brazilian municipalities in 2011 vs 614 in 2021), mostly reported in the North and Northeast regions of the country. There was a downward trend in vaccination coverages in 8 of the 27 States (p ≤ 0.05). Conclusions: The reduction in polio vaccine coverage, as observed in the North and Northeast regions of Brazil, may favor the spread of Poliovirus. Therefore, vaccination strategies should be prioritized for children residing in areas with sharp and recurrent declines in vaccination coverages, including travelers, migrants and refugees."
  },
  {
    "objectID": "publications/souzajuniorComparisonSamplingDesigns2022b.html#reference",
    "href": "publications/souzajuniorComparisonSamplingDesigns2022b.html#reference",
    "title": "Comparison of sampling designs from the two editions of the Brazilian National Health Survey, 2013 and 2019",
    "section": "Reference",
    "text": "Reference\n\n\nSOUZA JÚNIOR, P. R. B. DE et al. Comparison of sampling designs from the two editions of the Brazilian National Health Survey, 2013 and 2019. Cadernos de Saúde Pública, v. 38, p. e00164321, Jul. 2022."
  },
  {
    "objectID": "publications/souzajuniorComparisonSamplingDesigns2022b.html#abstract",
    "href": "publications/souzajuniorComparisonSamplingDesigns2022b.html#abstract",
    "title": "Comparison of sampling designs from the two editions of the Brazilian National Health Survey, 2013 and 2019",
    "section": "Abstract",
    "text": "Abstract\nOur objective is to describe the differences in the sampling plans of the two editions of the Brazilian National Health Survey (PNS 2013 and 2019) and to evaluate how the changes affected the coefficient of variation (CV) and the design effect (Deff) of some estimated indicators. Variables from different parts of the questionnaire were analyzed to cover proportions with different magnitudes. The prevalence of obesity was included in the analysis since anthropometry measurement in the 2019 survey was performed in a subsample. The value of the point estimate, CV, and the Deff were calculated for each indicator, considering the stratification of the primary sampling units, the weighting of the sampling units, and the clustering effect. The CV and the Deff were lower in the 2019 estimates for most indicators. Concerning the questionnaire indicators of all household members, the Deffs were high and reached values greater than 18 for having a health insurance plan. Regarding the indicators of the individual questionnaire, for the prevalence of obesity, the Deff ranged from 2.7 to 4.2, in 2013, and from 2.7 to 10.2, in 2019. The prevalence of hypertension and diabetes per Federative Unit had a higher CV and lower Deff. Expanding the sample size to meet the diverse health objectives and the high Deff are significant challenges for developing probabilistic household-based national survey. New probabilistic sampling strategies should be considered to reduce costs and clustering effects."
  },
  {
    "objectID": "publications/victor2023.html#reference",
    "href": "publications/victor2023.html#reference",
    "title": "Subset modelling: A domain partitioning strategy for data-efficient machine-learning",
    "section": "Reference",
    "text": "Reference\n\n\nRIBEIRO, V. et al. Subset modelling: A domain partitioning strategy for data-efficient machine-learning. Anais do XXXVIII simpósio brasileiro de bancos de dados. Anais...Porto Alegre, RS, Brasil: SBC, 2023."
  },
  {
    "objectID": "publications/victor2023.html#abstract",
    "href": "publications/victor2023.html#abstract",
    "title": "Subset modelling: A domain partitioning strategy for data-efficient machine-learning",
    "section": "Abstract",
    "text": "Abstract\nThe success of machine learning (ML) systems depends on data availability, volume, quality, and efficient computing resources. A challenge in this context is to reduce computational costs while maintaining adequate accuracy of the models. This paper presents a framework to address this challenge. The idea is to identify “subdomains” within the input space, train local models that produce better predictions for samples from that specific subdomain, instead of training a single global model on the full dataset. We experimentally evaluate our approach on two real-world datasets. Our results indicate that subset modelling (i) improves the predictive performance compared to a single global model and (ii) allows data-efficient training."
  }
]